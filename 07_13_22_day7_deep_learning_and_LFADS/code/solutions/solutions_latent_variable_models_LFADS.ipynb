{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7CZuGa48VD_"
      },
      "source": [
        "# Part 0: Learning Objectives and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What you will learn\n",
        "- Neural data preprocessing\n",
        " - - Binning\n",
        " - - Smoothing\n",
        " - - Aligning\n",
        "- Basic neural network training pipelines\n",
        "- - Poisson Loss\n",
        "- - Training Loops\n",
        "- - Evaluation Metrics\n",
        "- Autoencoders (AEs) applied to neural data \n",
        "- - Behavioral decoding\n",
        "- Basic flavors of Recurrent Neural Network (RNN)\n",
        "- - Linear\n",
        "- - GRU\n",
        "- Sequential Autoencoders (SAEs)\n",
        "- Variational Autoencoders(VAEs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SaberaTalukder/Chen_Institute_DataSAI_for_Neuroscience/blob/CV0713/07_13_22_day7_deep_learning_and_LFADS/code/solutions/solutions_latent_variable_models_LFADS.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMhAZ4_PFLBN"
      },
      "source": [
        "## Environment setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run this code to prepare the environment for this demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4esJ1y0fIrV"
      },
      "outputs": [],
      "source": [
        "## TODO: Run this once to set up your environment. Comment these out if you have to restart your notebook for speed.\n",
        "# !pip3 install torch\n",
        "# !pip3 install pytorch_lightning\n",
        "# !pip3 install torchvision\n",
        "# !pip3 install dandi\n",
        "# !pip3 install git+https://github.com/neurallatents/nlb_tools.git\n",
        "# !pip3 install cmasher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbVaWotNFO8J"
      },
      "source": [
        "## Data download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uncomment the line below to download the dataset into your colab notebook. We'll be using the dataset collected by Mark Churchland and first published in 2008 called the \"Maze Dataset\". It is publically available as part of the Neural Latents Benchmark contest (https://neurallatents.github.io/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJz17jzwFVYL",
        "outputId": "6c0fa54f-c419-4c57-a7f4-865c27c2a7d8"
      },
      "outputs": [],
      "source": [
        "## This downloads the dataset that we will be using for this workshop\n",
        "## Only needs to be run once\n",
        "!dandi download DANDI:000140/0.220113.0408\n",
        "!dandi download https://dandiarchive.org/dandiset/000138\n",
        "!mv 000140 ../../data/\n",
        "!mv 000138 ../../data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWGzkYw-FR19"
      },
      "source": [
        "## Imports and helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run this section once to get useful helper functions and imports. You shouldn't need to modify any of this code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97HAAhTWj4WO",
        "outputId": "8bd1e057-c2e8-458d-87bd-49b4150f181c"
      },
      "outputs": [],
      "source": [
        "## Generic imports and helper functions that we will use later in the notebook. Put here to reduce clutter.\n",
        "# Imports\n",
        "import os\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from nlb_tools.nwb_interface import NWBDataset\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import cmasher as cmr\n",
        "logger = logging.getLogger(__name__)\n",
        "from sklearn.decomposition import PCA\n",
        "from torch.autograd import Variable\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d   \n",
        "from scipy.stats import sem\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "import random\n",
        "random.seed(2022) \n",
        "def plot_cond_avg_latent_traj(latents_plot, conds_trial, conds_to_plot, kernel_size, cond_avg = True):\n",
        "    fig1 = plt.figure()\n",
        "    ax1 = fig1.add_subplot(111, projection=\"3d\")\n",
        "    latents_plot = smoothFiring(latents_plot, kernel_size = kernel_size, gaussian=True)\n",
        "    pca = PCA(n_components=3)\n",
        "    latents_pca = pca.fit_transform(latents_plot)\n",
        "    latents_pca = np.reshape(latents_pca, (75, 140, 3))\n",
        "    cmap = cmr.neon\n",
        "    colors = cmap(np.linspace(0, 1, len(conds_to_plot)))\n",
        "    for i, cond in enumerate(conds_to_plot):\n",
        "        trials = np.squeeze(latents_pca[conds_trial == cond, :,:])\n",
        "        n_trials = trials.shape[0]\n",
        "        alpha = np.linspace(0.5, 1, n_trials)\n",
        "        if not cond_avg:\n",
        "            for j in range(n_trials):\n",
        "                ax1.plot(trials[j,:,0], trials[j,:,1], trials[j,:,2], color =  colors[i,:], alpha = alpha[j])\n",
        "        else:\n",
        "            mean_trials = np.mean(trials, axis = 0)\n",
        "            ax1.plot(mean_trials[:,0], mean_trials[:,1], mean_trials[:,2],color =  colors[i,:], label = f\"cond {cond}\")\n",
        "    ax1.legend()\n",
        "    \n",
        "def scatter_latents(latents_in):\n",
        "    latents_all = latents_in\n",
        "    pca = PCA(n_components=3)\n",
        "    latents = pca.fit_transform(latents_all)\n",
        "\n",
        "    fig1 = plt.figure()\n",
        "    ax1 = fig1.add_subplot(111, projection=\"3d\")\n",
        "    ax1.scatter(*latents.T)\n",
        "    ax1.set_xlabel('x')\n",
        "    ax1.set_ylabel('y')\n",
        "    ax1.set_zlabel('z')\n",
        "# Plot Latent trajectories\n",
        "\n",
        "def plot_trials(trial_data, kernel_size, trial_nums, gaussian):\n",
        "    fig, axes = plt.subplots(3, len(trial_nums),  figsize = (5*len(trial_nums),15))\n",
        "    for i, trial_ind in enumerate(trial_nums):\n",
        "        trial = trial_data[trial_data['trial_id'] == trial_ind]\n",
        "        firing = np.float64(trial[\"spikes\"][:].to_numpy())\n",
        "        firing_smooth = smoothFiring(firing, kernel_size, gaussian= gaussian)\n",
        "        ax1 = axes[0][i]\n",
        "        ax1.imshow(firing_smooth.T,interpolation='nearest', aspect='auto')\n",
        "        t = np.linspace(0,len(firing_smooth[:,1]), len(firing_smooth[:,1]))\n",
        "        if i == 0:\n",
        "            ax1.set_ylabel('Neurons')\n",
        "        ax1.set_title(f\"Trial: {trial_ind}\")\n",
        "        ax1.set_xlim((0, 150))\n",
        "        ax2 = axes[1][i]\n",
        "        ax2.plot(t,trial[\"hand_vel\"][\"x\"],linewidth=3, label = \"x_vel\")\n",
        "        ax2.plot(t,trial[\"hand_vel\"][\"y\"],linewidth=3, label = \"y_vel\")\n",
        "        ax2.set_xlim(0, 150)\n",
        "        if i == 0:\n",
        "            ax2.set_xlabel('Time Bins')\n",
        "            ax2.set_ylabel(\"Hand Velocity (in x/y)\")\n",
        "            ax2.legend()\n",
        "\n",
        "        ax3 = axes[2][i]\n",
        "        ax3.plot(trial[\"hand_pos\"][\"x\"], trial[\"hand_pos\"][\"y\"],linewidth=3, color = 'k')\n",
        "        ax3.set_xlim((-165, 165))\n",
        "        ax3.set_ylim((-165, 165))\n",
        "        if i == 0:\n",
        "            ax3.set_xlabel('X Position')\n",
        "            ax3.set_ylabel(\"Y Position\")\n",
        "\n",
        "def plot_FR_conds(trial_data, kernel_size, cond_list, neuron_list, gaussian):\n",
        "    n_conds = len(cond_list)\n",
        "    n_time = 140\n",
        "    n_neurons = 107\n",
        "    cmap = cmr.neon\n",
        "    colors = cmap(np.linspace(0, 1, len(cond_list)))\n",
        "    fig, axes = plt.subplots(nrows=len(neuron_list)+2, ncols= 1,figsize = (8,5*len(neuron_list)), sharex= True)\n",
        "\n",
        "    mean_vel = np.zeros((n_time, 2, n_conds))\n",
        "    mean_fr = np.zeros((n_time, 107, n_conds))\n",
        "\n",
        "    std_vel = np.zeros((n_time, 2, n_conds))\n",
        "    std_fr = np.zeros((n_time, 107, n_conds))\n",
        "    for i, cond in enumerate(cond_list):\n",
        "        trials = trial_data[trial_data.trial_cond == cond]\n",
        "        grouped = list(trials.groupby('trial_id', sort=False))  \n",
        "        vel = np.stack([trial['hand_vel'].to_numpy() for _, trial in grouped])\n",
        "        fr = np.float64(np.stack([trial['spikes'].to_numpy() for _, trial in grouped]))\n",
        "        n_trials = len(grouped)\n",
        "        for j in range(n_trials):\n",
        "            fr[j,:, :] =  np.squeeze(smoothFiring(fr[j,:,:], kernel_size=kernel_size, gaussian = gaussian))*200\n",
        "        mean_vel[:,:,i] = np.mean(vel, axis = 0)\n",
        "        std_vel[:,:,i] = sem(vel, axis = 0)\n",
        "        mean_fr[:,:,i] = np.mean(fr, axis=0)\n",
        "        std_fr[:,:,i] = sem(fr, axis=0)\n",
        "\n",
        "    t = np.linspace(-250, 450, 140)\n",
        "    axX = axes[0]\n",
        "    axY = axes[1]\n",
        "\n",
        "    for i in range(len(cond_list)):\n",
        "        axX.plot(t, mean_vel[:,0,i],linewidth = 3, color = colors[i,:], label = f\"Condition {cond_list[i]}\")\n",
        "        axY.plot(t, mean_vel[:,1,i],linewidth = 3, color = colors[i,:])\n",
        "        axX.plot([0,0], [np.min(mean_vel[:,0]), np.max(mean_vel[:,0])],linewidth = 3,color ='k')\n",
        "        axY.plot([0,0], [np.min(mean_vel[:,1]), np.max(mean_vel[:,1])],linewidth = 3,color ='k')\n",
        "\n",
        "        axX.fill_between(\n",
        "                    t,\n",
        "                    mean_vel[:,0,i] - std_vel[:,0,i],\n",
        "                    mean_vel[:,0,i] + std_vel[:,0,i],\n",
        "                    color = colors[i,:],\n",
        "                    alpha=0.2,\n",
        "                )\n",
        "        axY.fill_between(\n",
        "                    t,\n",
        "                    mean_vel[:,1,i] - std_vel[:,1,i],\n",
        "                    mean_vel[:,1,i] + std_vel[:,1,i],\n",
        "                    color = colors[i,:],\n",
        "                    alpha=0.2,\n",
        "                )\n",
        "        axX.legend(loc = \"upper left\")\n",
        "\n",
        "    axX.set_xlabel('Time (ms)')\n",
        "    axX.set_ylabel(\"X Velocity (cm/s)\")\n",
        "\n",
        "    axY.set_xlabel('Time (ms)')\n",
        "    axY.set_ylabel(\"Y Velocity (cm/s)\")\n",
        "\n",
        "    for i, n_ind in enumerate(neuron_list):\n",
        "        ax = axes[i+2]\n",
        "        for j in range(len(cond_list)):\n",
        "            ax.plot(t, mean_fr[:,n_ind,j], linewidth = 3, color = colors[j,:])\n",
        "\n",
        "            ax.fill_between(\n",
        "                    t,\n",
        "                    mean_fr[:,n_ind,j] - std_fr[:,n_ind,j],\n",
        "                    mean_fr[:,n_ind,j] + std_fr[:,n_ind,j],\n",
        "                    color = colors[j,:],\n",
        "                    alpha=0.2,\n",
        "                )\n",
        "            a = 1\n",
        "        ax.set_ylabel(\"Firing Rate (hz)\")\n",
        "        ax.set_title(f\"Neuron {n_ind}\")\n",
        "        if i == len(neuron_list):\n",
        "            ax.set_xlabel(\"Time (ms)\")\n",
        "def plot_ics(ics_numpy, cond_arr):\n",
        "    fig2 = plt.figure()\n",
        "    ax2 = fig2.add_subplot(111, projection=\"3d\")\n",
        "    num_conds = len(np.unique(cond_arr))\n",
        "    cmap = cmr.neon\n",
        "    colors = cmap(np.linspace(0, 1, num_conds))\n",
        "    pca = PCA(n_components=3)\n",
        "    ic_pca = pca.fit_transform(ics_numpy)\n",
        "    for i  in range(num_conds):\n",
        "        ics_cond = ic_pca[cond_arr == i,:]\n",
        "        ax2.scatter(ics_cond[:,0], ics_cond[:,1], ics_cond[:,2], color = colors[i,:])\n",
        "      \n",
        "def to_tensor(array):\n",
        "    \"\"\"Converts a loaded numpy array to a tensor\n",
        "    and ensures correct dtype\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    array : np.array\n",
        "        The numpy array to convert.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        The converted tensor.\n",
        "    \"\"\"\n",
        "    return torch.tensor(array, dtype=torch.float)\n",
        "    \n",
        "def plot_smoothed_latent_trajs(latents_plot, num_trials, kernel_size):\n",
        "    cmap = cmr.rainforest\n",
        "    colors = cmap(np.linspace(0, 1, num_trials))\n",
        "    fig2 = plt.figure()\n",
        "    ax2 = fig2.add_subplot(111, projection=\"3d\")\n",
        "    fig3 = plt.figure()\n",
        "    ax3 = fig3.add_subplot(111)\n",
        "    n_trials, n_steps, n_latents = latents_plot.shape\n",
        "    pca = PCA(n_components=3)\n",
        "    latents_flat = latents_plot.reshape(-1, n_latents)\n",
        "    latents_plot = pca.fit_transform(latents_flat)\n",
        "    latents_plot = latents_plot.reshape(n_trials, n_steps, 3)\n",
        "    t = np.linspace(0, n_steps, n_steps)\n",
        "    explained_variance = np.sum(pca.explained_variance_ratio_)\n",
        "    latents_smooth = np.zeros_like(latents_plot)\n",
        "    for i in range(num_trials):\n",
        "        latents_trial = np.float64(np.squeeze(latents_plot[i,:,:]))\n",
        "        latents_trial = smoothFiring(latents_trial, kernel_size, gaussian=True)\n",
        "        latents_smooth[i,:,:] = latents_trial\n",
        "        ax2.plot(latents_trial[:, 0], latents_trial[:,1], latents_trial[:,2], color = colors[i,:])\n",
        "        ax3 = fig3.add_subplot(num_trials, 1, i+1)\n",
        "        ax3.plot(t, latents_trial[:,0], color = 'r')\n",
        "        ax3.plot(t, latents_trial[:,1], color = 'g')\n",
        "        ax3.plot(t, latents_trial[:,2], color = 'b')\n",
        "\n",
        "def plot_pred_FR(pred_rates_plot, rates_plot, num_trials, kernel_size):\n",
        "    cmap = cmr.rainforest\n",
        "    colors = cmap(np.linspace(0, 1, num_trials))\n",
        "    fig, axes = plt.subplots(1, num_trials,  figsize = (10*num_trials,15))\n",
        "    n_trials, n_steps, n_neurons = rates.shape\n",
        "\n",
        "    t = np.linspace(-250, 350, n_steps)\n",
        "    rates_smooth = np.zeros_like(rates_plot)\n",
        "    pred_rates_smooth = np.zeros_like(pred_rates_plot)\n",
        "    for i in range(num_trials):\n",
        "        ax1 = axes[i]\n",
        "        rates_trial = np.squeeze(rates_plot[i,:,:])\n",
        "        rates_trial = smoothFiring(rates_trial, kernel_size, gaussian=True)\n",
        "        rates_smooth[i,:,:] = rates_trial\n",
        "        pred_rates_trial = np.squeeze(pred_rates_plot[i,:,:])\n",
        "        pred_rates_trial = smoothFiring(pred_rates_trial, kernel_size, gaussian=True)\n",
        "        ax1.plot(t, rates_trial[:,0]*200, color = 'r')\n",
        "        ax1.plot(t, rates_trial[:,1]*200, color = 'g')\n",
        "        ax1.plot(t, rates_trial[:,2]*200, color = 'b')\n",
        "    ax1.set_xlabel('Time (ms)')\n",
        "    ax1.set_ylabel('Firing rate (hz)')\n",
        "\n",
        "def add_conds_to_trial_data(trial_data_in, dataset_in):\n",
        "    cond_fields = ['trial_type', 'trial_version']\n",
        "    combinations = sorted(dataset_in.trial_info[cond_fields].dropna().set_index(cond_fields).index.unique().tolist())\n",
        "    combinations = np.array(combinations)\n",
        "    trial_data = trial_data_in.copy()\n",
        "    trial_info = dataset_in.trial_info\n",
        "    trial_nums = trial_info.trial_id.values\n",
        "    trial_data['trial_cond'] = np.zeros(len(trial_data))\n",
        "    for i,comb in enumerate(combinations):\n",
        "        # Need a list of all the trial_ids that match cond\n",
        "        flag1 = trial_info.trial_type.values == comb[0]\n",
        "        flag2 = trial_info.trial_version.values == comb[1]\n",
        "        flag3 = np.logical_and(flag1, flag2)\n",
        "        trial_flag =np.where(flag3) # a list of indices in trial_info that\n",
        "        cond_trials = trial_nums[trial_flag]\n",
        "        trial_data.loc[np.isin(trial_data.trial_id, cond_trials),'trial_cond'] = i\n",
        "    return trial_data\n",
        "\n",
        "\n",
        "def plotPredictedFR(predFR, spiking, unitNum, kernel_size, window):\n",
        "    fig1 = plt.figure()\n",
        "    ax1 = fig1.add_subplot(111)\n",
        "    n_data,n_units = predFR.shape\n",
        "    smoothSpiking = smoothFiring(spiking, kernel_size)\n",
        "    smoothPred = smoothFiring(predFR, kernel_size=kernel_size)\n",
        "    t = np.linspace(0, 5*n_data/1000, n_data)\n",
        "    ax1.plot(t[window[0]:window[1]], smoothPred[window[0]:window[1], unitNum]*200, label = \"predicted\")\n",
        "    ax1.plot(t[window[0]:window[1]], smoothSpiking[window[0]:window[1], unitNum]*200, label = \"True\")\n",
        "    ax1.set_title(f\"Neuron: {i}\")\n",
        "    ax1.legend()\n",
        "    ax1.set_xlabel(\"Time (s)\")\n",
        "    ax1.set_ylabel(\"Firing Rate (hz)\")\n",
        "\n",
        "def simulate_system(A, n_inits, n_steps):\n",
        "    print(A)\n",
        "    inits = np.random.rand(n_inits,2)-0.5\n",
        "    states = np.zeros((n_inits, n_steps, 2))\n",
        "    for i in range(n_inits):\n",
        "        state = inits[i,:]\n",
        "        for j in range(n_steps):\n",
        "            states[i,j,:] = state\n",
        "            state = np.matmul(A, state)\n",
        "    \n",
        "    fig1 = plt.figure()\n",
        "    ax1 = fig1.add_subplot(111)\n",
        "    for i in range(n_inits):\n",
        "        ax1.plot(states[i,:,0], states[i,:,1], color = 'k', linewidth = 0.5)\n",
        "        ax1.scatter(states[i,0,0], states[i,0,1], color = 'g')\n",
        "        ax1.scatter(states[i,-1,0], states[i,-1,1], color = 'r')\n",
        "\n",
        "def simulate_3D_system(A, init_state, n_steps):\n",
        "    print(A)\n",
        "    states = np.zeros((n_steps, 3))\n",
        "    state = init_state\n",
        "    for j in range(n_steps):\n",
        "        states[j,:] = state\n",
        "        state = np.matmul(A, state)\n",
        "\n",
        "    fig1 = plt.figure()\n",
        "    ax1 = fig1.add_subplot(111, projection = \"3d\")\n",
        "\n",
        "    ax1.plot(states[:,0], states[:,1], states[:,2], color = 'k', linewidth = 0.5)\n",
        "    ax1.scatter(states[0,0], states[0,1], states[0,2], color = 'g')\n",
        "    ax1.scatter(states[-1,0], states[-1,1], states[-1,2], color = 'r')    \n",
        "    ax1.set_xlim([0,1])\n",
        "    ax1.set_ylim([0,1])\n",
        "    ax1.set_zlim([0,1])\n",
        "    ax1.set_xlabel(\"X\")\n",
        "    ax1.set_ylabel(\"Y\")\n",
        "    ax1.set_zlabel(\"Z\")\n",
        "    ax1.set_title(\"Three Neuron Dynamics\")\n",
        "    ax1.view_init(30, 30)        \n",
        "    \n",
        "def computeHandVelR2(model, ds_array_train, kernel_size_in, gaussian = True):\n",
        "    pred_rates_flat, latents_all = model(ds_array_train[0])\n",
        "\n",
        "    # Get the data into Numpy arrays\n",
        "    pred_rates_flat2 = torch.clone(pred_rates_flat)\n",
        "    pred_rates_flat2 = pred_rates_flat2.detach().numpy()\n",
        "    latents_all2 = torch.clone(latents_all)\n",
        "    latents_all2 = latents_all2.detach().numpy()\n",
        "    rates2 = torch.clone(ds_array_train[0])\n",
        "    rates2 = rates2.detach().numpy()\n",
        "    vel = ds_array_train[2]\n",
        "    vel2 = torch.clone(vel)\n",
        "    vel2 = vel2.detach().numpy()\n",
        "\n",
        "    # Reshape the data into a trialized format to eliminate smoothing artifacts\n",
        "    latents_all2 = np.reshape(latents_all2, (75, 140, 20))\n",
        "    pred_rates2 = np.reshape(pred_rates_flat2, (75, 140, 142))\n",
        "    rates2 = np.reshape(rates2, (75, 140, 107))\n",
        "\n",
        "    # Initialize some variables for smoothing and our model fits\n",
        "    n_trials, n_bins,  n_latents = latents_all2.shape\n",
        "    latents_smooth = np.zeros((n_trials, n_bins, n_latents))\n",
        "    rates_smooth = np.zeros((n_trials, n_bins, 107))\n",
        "    pred_rates_smooth = np.zeros((n_trials, n_bins, 142))\n",
        "\n",
        "    r2LatentHeldout= np.zeros(35)\n",
        "    r2InputHeldout = np.zeros(35)\n",
        "    r2PredHeldout = np.zeros(35)\n",
        "\n",
        "    # Smooth our data with the specified smoothing window (using gaussian by default here)\n",
        "    for i in range(latents_all2.shape[0]):\n",
        "        latents_smooth[i,:,:] = smoothFiring(np.squeeze(latents_all2[i,:,:]), kernel_size_in, gaussian= gaussian)\n",
        "        rates_smooth[i,:,:] = smoothFiring(np.squeeze(rates2[i,:,:]), kernel_size_in, gaussian= gaussian)\n",
        "        pred_rates_smooth[i,:,:] = smoothFiring(np.squeeze(pred_rates2[i,:,:]), kernel_size_in, gaussian= gaussian)\n",
        "\n",
        "    # Reshape our data into 2D arrays for linear regression\n",
        "    latents_fit = latents_smooth.reshape((-1, n_latents))\n",
        "    rates_fit = rates_smooth.reshape((-1, 107))\n",
        "    pred_rates_fit = pred_rates_smooth.reshape((-1, 142))\n",
        "    pred_rates_fit = pred_rates_fit[:,:107]\n",
        "\n",
        "    # Fit a linear model to our heldout neurons from latents, input neurons, and decoded neurons\n",
        "    for i in range(34):\n",
        "        regLatent = LinearRegression().fit(latents_fit, pred_rates_flat2[:,108+i])\n",
        "        r2LatentHeldout[i] = regLatent.score(latents_fit, pred_rates_flat2[:, 108+i])\n",
        "\n",
        "        regInput = LinearRegression().fit(rates_fit, pred_rates_flat2[:,108+i])\n",
        "        r2InputHeldout[i] = regInput.score(rates_fit, pred_rates_flat2[:, 108+i])\n",
        "\n",
        "        regPred = LinearRegression().fit(pred_rates_fit, pred_rates_flat2[:,108+i])\n",
        "        r2PredHeldout[i] = regPred.score(pred_rates_fit, pred_rates_flat2[:, 108+i])\n",
        "\n",
        "    # Fit linear regression model from latents, input, and decoded neural activity to hand velocity\n",
        "    regX = LinearRegression().fit(latents_fit, vel2[:,0])\n",
        "    regY = LinearRegression().fit(latents_fit, vel2[:,1])\n",
        "\n",
        "    regRatesX = LinearRegression().fit(rates_fit, vel2[:,0])\n",
        "    regRatesY = LinearRegression().fit(rates_fit, vel2[:,1])\n",
        "\n",
        "    regPredRatesX = LinearRegression().fit(pred_rates_fit, vel2[:,0])\n",
        "    regPredRatesY = LinearRegression().fit(pred_rates_fit, vel2[:,1])    \n",
        "\n",
        "    r2X =  regX.score(latents_fit, vel2[:,0])\n",
        "    r2Y =  regY.score(latents_fit, vel2[:,1])\n",
        "\n",
        "    r2rateX = regRatesX.score(rates_fit, vel2[:,0])\n",
        "    r2rateY = regRatesY.score(rates_fit, vel2[:,1])\n",
        "\n",
        "    r2PredRateX = regPredRatesX.score(pred_rates_fit, vel2[:,0])\n",
        "    r2PredRateY = regPredRatesY.score(pred_rates_fit, vel2[:,1])\n",
        "\n",
        "\n",
        "    print(f\"R2 of X vel decoding from neurons: {r2rateX}\")\n",
        "    print(f\"R2 of X vel decoding from latents: {r2X}\")\n",
        "    print(f\"R2 of X vel decoding from autoencoded neurons: {r2PredRateX}\\n\")\n",
        "\n",
        "    print(f\"R2 of Y vel decoding from neurons: {r2rateY}\")\n",
        "    print(f\"R2 of Y vel decoding from latents: {r2Y}\")\n",
        "    print(f\"R2 of Y vel decoding from autoencoded neurons: {r2PredRateY}\\n\")\n",
        "\n",
        "\n",
        "    print(f\"R2 of heldout neuron decoding from neurons: {np.mean(r2InputHeldout)}\")\n",
        "    print(f\"R2 of heldout neuron decoding from latents: {np.mean(r2LatentHeldout)}\")\n",
        "    print(f\"R2 of heldout neuron decoding from autoencoded neurons: {np.mean(r2PredHeldout)}\")\n",
        "\n",
        "       \n",
        "def computeHandVelR2Tensor(model, ds_tensor_train, kernel_size_in, gaussian = True):\n",
        "    pred_rates, latents_all = model(ds_tensor_train[0])\n",
        "\n",
        "    # Get the data into Numpy arrays\n",
        "    pred_rates2 = torch.clone(pred_rates)\n",
        "    pred_rates2 = pred_rates2.detach().numpy()\n",
        "    latents_all2 = torch.clone(latents_all)\n",
        "    latents_all2 = latents_all2.detach().numpy()\n",
        "    rates2 = torch.clone(ds_tensor_train[1])\n",
        "    rates2 = rates2.detach().numpy()\n",
        "    vel = ds_tensor_train[2]\n",
        "    vel2 = torch.clone(vel)\n",
        "    vel2 = vel2.detach().numpy()\n",
        "\n",
        "    # Initialize some variables for smoothing and our model fits\n",
        "    n_trials, n_bins_in, n_heldin = rates2.shape\n",
        "    n_trials, n_bins_fwd,  n_latents = latents_all2.shape\n",
        "    latents_smooth = np.zeros((n_trials, n_bins_fwd, n_latents))\n",
        "    rates_smooth = np.zeros((n_trials, n_bins_in, 142))\n",
        "    pred_rates_smooth = np.zeros((n_trials, n_bins_fwd, 142))\n",
        "\n",
        "    heldout = ds_tensor_train[1]\n",
        "    heldout2 = torch.clone(heldout)\n",
        "    heldout2 = heldout2.detach().numpy()\n",
        "\n",
        "    r2LatentHeldout= np.zeros(35)\n",
        "    r2InputHeldout = np.zeros(35)\n",
        "    r2PredHeldout = np.zeros(35)\n",
        "    # Smooth our data with the specified smoothing window (using gaussian by default here)\n",
        "    for i in range(latents_all2.shape[0]):\n",
        "        latents_smooth[i,:,:] = smoothFiring(np.squeeze(latents_all2[i,:,:]), kernel_size_in, gaussian= gaussian)\n",
        "        rates_smooth[i,:,:] = smoothFiring(np.squeeze(rates2[i,:,:]), kernel_size_in, gaussian= gaussian)\n",
        "        pred_rates_smooth[i,:,:] = smoothFiring(np.squeeze(pred_rates2[i,:,:]), kernel_size_in, gaussian= gaussian)\n",
        "\n",
        "    # Reshape our data into 2D arrays for linear regression\n",
        "    latents_fit = latents_smooth.reshape((-1, n_latents))\n",
        "    rates_fit = rates_smooth.reshape((-1, 142))\n",
        "    rates_fit = rates_fit[:,:107]\n",
        "    pred_rates_fit = pred_rates_smooth.reshape((-1, 142))\n",
        "    pred_rates_fit = pred_rates_fit[:,:107]\n",
        "    heldout_fit = heldout2.reshape((-1, 142))\n",
        "\n",
        "\n",
        "    # Fit a linear model to our heldout neurons from latents, input neurons, and decoded neurons\n",
        "    for i in range(34):\n",
        "        regLatent = LinearRegression().fit(latents_fit, heldout_fit[:,108+i])\n",
        "        r2LatentHeldout[i] = regLatent.score(latents_fit, heldout_fit[:, 108+i])\n",
        "\n",
        "        regInput = LinearRegression().fit(rates_fit, heldout_fit[:,108+i])\n",
        "        r2InputHeldout[i] = regInput.score(rates_fit, heldout_fit[:, 108+i])\n",
        "\n",
        "        regPred = LinearRegression().fit(pred_rates_fit, heldout_fit[:,108+i])\n",
        "        r2PredHeldout[i] = regPred.score(pred_rates_fit, heldout_fit[:, 108+i])\n",
        "\n",
        "    latents_fit2 = latents_smooth[:, :140,:]\n",
        "    latents_fit2 = latents_fit2.reshape(-1, n_latents)\n",
        "    # Fit linear regression model from latents, input, and decoded neural activity to hand velocity\n",
        "\n",
        "    vel2 = vel2.reshape(-1,2)\n",
        "\n",
        "    rates_fit2 = rates_smooth[:,:140, :107]\n",
        "    rates_fit2 =rates_fit2.reshape((-1, 107))\n",
        "\n",
        "    pred_rates_fit2 = pred_rates_smooth[:,:140,:107]\n",
        "    pred_rates_fit2 = pred_rates_fit2.reshape((-1, 107))\n",
        "    regX = LinearRegression().fit(latents_fit2, vel2[:,0])\n",
        "    regY = LinearRegression().fit(latents_fit2, vel2[:,1])\n",
        "\n",
        "    regRatesX = LinearRegression().fit(rates_fit2, vel2[:,0])\n",
        "    regRatesY = LinearRegression().fit(rates_fit2, vel2[:,1])\n",
        "\n",
        "    regPredRatesX = LinearRegression().fit(pred_rates_fit2, vel2[:,0])\n",
        "    regPredRatesY = LinearRegression().fit(pred_rates_fit2, vel2[:,1])    \n",
        "\n",
        "    r2X =  regX.score(latents_fit2, vel2[:,0])\n",
        "    r2Y =  regY.score(latents_fit2, vel2[:,1])\n",
        "\n",
        "    r2rateX = regRatesX.score(rates_fit2, vel2[:,0])\n",
        "    r2rateY = regRatesY.score(rates_fit2, vel2[:,1])\n",
        "\n",
        "    r2PredRateX = regPredRatesX.score(pred_rates_fit2, vel2[:,0])\n",
        "    r2PredRateY = regPredRatesY.score(pred_rates_fit2, vel2[:,1])\n",
        "\n",
        "\n",
        "    print(f\"R2 of X vel decoding from neurons: {r2rateX}\")\n",
        "    print(f\"R2 of X vel decoding from latents: {r2X}\")\n",
        "    print(f\"R2 of X vel decoding from autoencoded neurons: {r2PredRateX}\\n\")\n",
        "\n",
        "    print(f\"R2 of Y vel decoding from neurons: {r2rateY}\")\n",
        "    print(f\"R2 of Y vel decoding from latents: {r2Y}\")\n",
        "    print(f\"R2 of Y vel decoding from autoencoded neurons: {r2PredRateY}\\n\")\n",
        "\n",
        "\n",
        "    print(f\"R2 of heldout neuron decoding from neurons: {np.mean(r2InputHeldout)}\")\n",
        "    print(f\"R2 of heldout neuron decoding from latents: {np.mean(r2LatentHeldout)}\")\n",
        "    print(f\"R2 of heldout neuron decoding from autoencoded neurons: {np.mean(r2PredHeldout)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk_B-iE48eMU"
      },
      "source": [
        "# Part 1: Neural Dynamics and Maze Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What are neural dynamics?\n",
        "\n",
        "Neurons are cells that are connected together in a network. They communicate using action potentials, electrical impulses that transmit information across synapses.\n",
        "\n",
        "Consider a set of three neurons that are wired together with a very specific arrangement, depicted below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/Dyn1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are three things to take away from this diagram\n",
        " 1. The \"state\" of this network is defined as the vector of the neurons' instantaneous firing rates\n",
        " 2. The state develops as a function of the current activity\n",
        " 3. The strength of the three synapses determines how the state will develop\n",
        "\n",
        "These three points can be summarized in three equations, which I provide below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/Dyn2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take a minute (without running the next cell!) to think about what the activity of this network would look like if the network were to have an initial firing rate of $N_{0}$ = [1,0,0].\n",
        "\n",
        "Draw a 3D plot of how the state would evolve over time. X, Y, and Z should correspond to the x,y, and z axes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/Dyn3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interestingly, if we were to record from this simple neural circuit, we would find that despite the system having 3 neurons (i.e., a 3 dimensional system), the neural activity produced from these initial conditions only has two dimensions.\n",
        "\n",
        "No matter how long you run this circuit forwards in time, the activity will never leave this 2D plane in the 3D neural space.\n",
        "\n",
        "This lower dimensional representation of dynamics can be called the circuit's **Latent Dynamics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/Dyn4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This simple example captures all of the principles that I would like you to take away from the workshop today:\n",
        "- Neural dynamics describe how neural activity develops over time.\n",
        "- These dynamics arise (at least in part) from how the neurons in a network are connected to one another\n",
        "- These dynamics often fall on a lower-dimensional space than the number of neurons in the network.\n",
        "  - These are often called \"latent\" dynamics\n",
        "- We can use mathematical models to capture these latent dynamics\n",
        "\n",
        "Now we're going to dig into the data we are going to use to explore latent dynamics!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "613vo76k8kaA"
      },
      "source": [
        "## Overview of Maze Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This dataset was collected from primary motor cortex (M1) and dorsal premotor cortex (PMd). A basic description can be found in the blurb on the NLB datasets page: https://neurallatents.github.io/datasets\n",
        "\n",
        "    The maze task is a delayed center-out reach task with barriers, resulting in a variety of straight and curved trajectories. Neural activity was recorded from the dorsal premotor and primary motor cortices, and cursor, monkey gaze position, and monkey hand position and velocity are also provided.\n",
        "\n",
        "    It has been found that M1/PMd activity during such planned, highly-stereotyped movements is predictable from neural population state at movement onset. Though this does not imply the neural system is itself autonomous, predictability makes the dataset useful for evaluating a method’s ability to model autonomous dynamics. In addition to a standard session, we provide 3 recording sessions (standard, large, medium, and small) with varying numbers of trials in order to test how modeling methods scale to limited data.\n",
        "\n",
        "    The 4 recording sessions we are releasing are provided by Matt Kaufman, Mark Churchland, and Krishna Shenoy at Stanford University.\n",
        "We will be using the \"small\" version for ease of computational resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/maze_fig1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First things first: We want to deal with the data in a manageable bin size: Currently it is binned a 1 ms bin widths, which means that the vast majority of bins have no spikes in them. We're going to move to a larger bin size (5 ms) for convenience. This will let us train models more quickly and more easily inspect the firing rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNBbZJIDE1wH",
        "outputId": "903df964-0986-4e17-d37e-dd8af343a00b"
      },
      "outputs": [],
      "source": [
        "## Get the current path and pull the dataset into the Neurodata Without Borders format\n",
        "curr_path = os.getcwd()\n",
        "fpath = \"../../data/000140/sub-Jenkins/\"\n",
        "os.listdir(fpath) \n",
        "\n",
        "dataset = NWBDataset(fpath=fpath) \n",
        "\n",
        "## Resample the dataset to 20 ms bin size\n",
        "print(f'Data shape: {dataset.data.shape}')\n",
        "print(f'Bin width: {dataset.bin_width} ms')\n",
        "dataset.resample(5)\n",
        "print(f'Resampled data shape: {dataset.data.shape}')\n",
        "print(f'Resampled bin width: {dataset.bin_width} ms')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C13BJ-Nv8pz6"
      },
      "source": [
        "## Inspecting the Maze dataset\n",
        "Now we're going to look at the dataset and see what it's components are. We'll start with one field, the \"trial_info\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "vCqCGJ6alJp5",
        "outputId": "66630fdc-e552-4d60-a393-8e4921862134"
      },
      "outputs": [],
      "source": [
        "## Inspect the fields available to you\n",
        "print(dataset.trial_info.keys())\n",
        "dataset.trial_info[\"split\"]\n",
        "dataset.trial_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see there is a lot of important info in this structure: In general, each row represents a single trial. Each entry has a start time, end time, movement onset time, what type of trial it is, etc. \n",
        "\n",
        "**Importantly, this dataset has the train/val/test split done for us already, so we will use these flags in our training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A second important field is the data itself:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(dataset.data.keys())\n",
        "dataset.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking at the data, we can see that there are cursor and eye positions, hand positions and velocities, and spikes.\n",
        "\n",
        "**There is an important distinction between \"heldout_spikes\" and \"spikes\".** \n",
        "\n",
        "To explain what this means, take a look at the figure below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/FRTensor.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**A major goal for our model of neural data is to be able to capture features of the data that were not explicitly trained.** \n",
        "\n",
        "For this reason, when we train our models we are going to: \n",
        "1. Hide some neurons from the encoders. (Held-out neurons)\n",
        "2. Ask the decoders to model the whole trial, not just the section we train it on. (ie., make forward predictions)\n",
        "\n",
        "**If our model can successfully model the neurons that the encoder doesn't see and predict future neural activity, then we have some assurance that the model is capturing something useful in the underlying data.**\n",
        "\n",
        "The red rectangle above represents the neurons that we will be leaving out from our models, while the blue rectangle are \"forward predictions\". We will discuss what these mean in more detail a bit later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trializing neural data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make it easier for us to inspect the data, we will want to convert it into a \"trialized\" format, where all the data for each trial is grouped together.\n",
        "\n",
        "Luckily, this process can be simplified with a function from the NLB toolkit called \"make_trial_data\". This function takes in a flag that designates the landmark in the trial\n",
        "to align the data to and a range around which to align. It returns a trial-based collection of data. \n",
        "\n",
        "We will use default trimming parameters of [move_onset_time-250, move_onset_time+450].\n",
        "\n",
        "**Feel free to play around with these settings to see how changes in the trial window affects our results!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trial_data = dataset.make_trial_data(align_field = \"move_onset_time\", align_range = (-250, 450))\n",
        "trial_data = add_conds_to_trial_data(trial_data_in= trial_data, dataset_in= dataset)\n",
        "print(trial_data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see in the output above, each row of the trial_data structure has a \"trial_id\" field, which we can use to segregate out trials more easily for future analysis. \n",
        "\n",
        "For now, we want to visualize what these data look like. Unfortunately, the discretely-valued spiking data can be hard to visually inspect, so we are going to want to code up a function that will give us a general idea of how these neurons behave while the monkey performs the task. For that, we will spin up a basic moving-average smoothing function, which replaces the number of spikes in a given bin with the average number of spikes in a window surrouding the time point of a specific size (padding the ends of the trial with zeros to maintain its length). \n",
        "\n",
        " **A small smoothing window will leave the data largely untouched, while a large smoothing window might \"smooth over\" useful information.** \n",
        " \n",
        " Choosing how to smooth your data can be a very important decision that can significantly affect subsequent analyses.\n",
        " \n",
        "To give an example, a moving average filter of width 3 will transform firing rates of \n",
        " \n",
        " >[0,  0,    0,    3,    0,    0,   0, 0, 0] \n",
        " \n",
        " into \n",
        " \n",
        " >[0,  0,    1,    1,    1,    0,   0, 0, 0]\n",
        "\n",
        " while a moving average filter of width 5 width transform it into\n",
        " \n",
        " >[0, 0.66, 0.66, 0.66, 0.66, 0.66, 0, 0, 0]\n",
        "\n",
        " I've included a graphical example of how a moving average filter works below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/Convolution.gif)\n",
        "https://datascience.stackexchange.com/questions/26290/example-of-1d-convnet-filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In practice, a moving-average filter is not usually a very good choice as it can make the data look choppy and hard to interpret. \n",
        "\n",
        "It is, however, quite simple to code.\n",
        "\n",
        "So we can inspect our data more closely as our analyses get more sophisticated, I've also included a 1D Gaussian filter that will help you visualize the data more easily than the moving average filter. \n",
        "\n",
        " **Until then, complete the moving average filter below, then run this section.** \n",
        " \n",
        " **If your code works properly, you should see plots that will help you get a sense for how neurons in M1 modulate their firing during this reaching task**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpJeUH02qyLs"
      },
      "outputs": [],
      "source": [
        "# Visualize smoothed firing rates\n",
        "def smoothFiring(data, kernel_size, gaussian = True):\n",
        "    ## TODO: Run a moving-average smoothing filter over the firing rates\n",
        "    ## Hint: See np.convolve\n",
        "    if kernel_size > 1:\n",
        "        if gaussian:\n",
        "            for i  in range(data.shape[1]):\n",
        "                data[:,i] = gaussian_filter1d(data[:,i], kernel_size)\n",
        "\n",
        "        else:\n",
        "            kernel = np.ones(kernel_size) / kernel_size\n",
        "            for i in range(data.shape[1]):\n",
        "                data[:,i] = np.convolve(data[:,i], kernel, mode= \"same\")\n",
        "    #-------------------------------------------\n",
        "    return data\n",
        "\n",
        "trials_to_plot = [110, 111,112]\n",
        "kernel_size = 10\n",
        "# Play around and plot a few different trials to see how the behavior looks\n",
        "plot_trials(trial_data, kernel_size = kernel_size, trial_nums = trials_to_plot, gaussian = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you can see the firing of all of the neurons at once for a trial, but it can be difficult to translate this into an understanding of what is going on at the single neuron level.\n",
        "\n",
        "To aid in this endeavor, I've provided a second plotting function (that also uses your *smoothFiring* function). Instead of plotting individual trials, I've instead plot the condition-averaged hand velocities and neural firing rates, along with bars that indicate the standard error about the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cond_list = np.arange(3, 7)\n",
        "neuron_list =np.arange(0,10)\n",
        "plot_FR_conds(trial_data, kernel_size = kernel_size, cond_list = cond_list, neuron_list= neuron_list, gaussian = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take 10 minutes or so to dig around the neural and behavioral data to get a feel for the basic properties of the neural activity.\n",
        "\n",
        "**Some things to look for:**\n",
        "- When do these neurons typically change their firing rates during the trial?\n",
        "- Do these neurons typically increase or decrease their firing rates?\n",
        "- Can you find any neurons that are strongly related to the hand velocity (or hand position)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu3Aoeqi8wp3"
      },
      "source": [
        "## Trim and package data for training\n",
        "\n",
        "### Dataloaders\n",
        "\n",
        "We are going to use PyTorch to train our models, so we now we need to put the data in a format that PyTorch can easily use. \n",
        "\n",
        "The standard PyTorch object used to feed data to models is known as a DataLoader. \n",
        "\n",
        "**A DataLoader is an object that returns batches of data for training and validation of deep learning models.**\n",
        "\n",
        "Batch size is an important parameter for training models with Stochastic Gradient Descent (SGD).\n",
        "- Small batch sizes can lead to high variance in estimates of the gradient\n",
        "- Large batch sizes can make training extremely slow and memory-intensive.\n",
        "\n",
        "The DataLoaders handle the process of grabbing batches of data from the dataset and feeding them to your model during the training and validation loops. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your task:\n",
        "\n",
        "**We will make four dataloaders in total**\n",
        "- 2D training dataloader\n",
        "- 2D validation dataloader\n",
        "- 3D training dataloader\n",
        "- 3D validation dataloader\n",
        "\n",
        "**Each dataloader should return four fields**\n",
        "- heldin spiking, \n",
        "- reconstructed spiking \n",
        "- hand velocities (for comparing model performance)\n",
        "- Condition information\n",
        "\n",
        "The 2D dataloaders should return spiking activity that is \"stacked\" across trials (i.e., a 2D Tensor of dimension (BxT) x N, where B is the number of trials, T is the trial length, and N is the number of neurons), while the 3D dataloaders should return a 3D spiking tensor (BxTxN).\n",
        "\n",
        "We will use these array and tensor dataloaders for our vanilla autoencoders and sequential autoencoders respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Complete the missing code to construct the dataloaders!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_array_dataloader(dataset, spk_field, hospk_field, align_field, align_window,\n",
        "                    trial_split):\n",
        "    # TODO: Complete the missing sections of this code\n",
        "    # Inputs: dataset-      The NWB dataset (not the trialized format) that will be the source of the training/validation data\n",
        "    #         spk_field-    A string that represents the field of \"heldin\" spikes, in this case \"spikes\"\n",
        "    #         hospk_field-  A string containing the field of \"heldout\" spikes, in this case \"heldout_spikes\"\n",
        "    #         align_field-  A string containing the field on which the trials should be aligned. Typically \"move_onset_time\"\n",
        "    #         align_window- A tuple of ints that designate how to cut the trials around the alignment window (in ms)\n",
        "    #         trial_split-  The trials to be used to generate the dataloader (\"train\" or \"val\")\n",
        "    # \n",
        "    # Returns: dataloader-  DataLoader object containing a 2D tensor with dimension (BxT) x N, where B is the number of trials, T is the trial length, and N is the number of neurons \n",
        "    #          dataset-     List containing 3 Tensor objects, the heldin spiking, the reconstructed spiking, and the velocity.\n",
        "\n",
        "    split_to_mask = lambda x: (dataset.trial_info.split == x) if isinstance(x, str) else x\n",
        "    trial_mask = split_to_mask(trial_split)\n",
        "    allow_nans = trial_split != \"train\"\n",
        "    trial_data = dataset.make_trial_data(ignored_trials=~trial_mask, allow_nans=allow_nans, align_field = align_field, align_range = align_window)\n",
        "    trial_data = add_conds_to_trial_data(trial_data, dataset)\n",
        "\n",
        "    # ---------------------For the students -----------------------------------\n",
        "    # These lines should pull the required spiking data from the trial_data structure\n",
        "    heldin = torch.Tensor(trial_data[spk_field].to_numpy())\n",
        "    heldout = torch.Tensor(trial_data[hospk_field].to_numpy())\n",
        "    vel = torch.Tensor(trial_data[\"hand_vel\"].to_numpy())\n",
        "    conds = torch.Tensor(trial_data[\"trial_cond\"].to_numpy())\n",
        "    # --------------------------------------------------------------------------\n",
        "\n",
        "    print(f\"Shape of heldin array {heldin.shape}.\")\n",
        "    print(f\"Shape of heldout array {heldout.shape}.\")\n",
        "    print(f\"Shape of vel array {vel.shape}.\")\n",
        "\n",
        "    recon_data = torch.cat([heldin, heldout], dim =1)\n",
        "\n",
        "    tensors = [heldin, recon_data, vel, conds]\n",
        "    array_dataset = TensorDataset(heldin, recon_data, vel, conds)\n",
        "\n",
        "\n",
        "    dataloader = DataLoader(array_dataset,\n",
        "                                batch_size = 200,\n",
        "                                num_workers = 4,\n",
        "                                shuffle = True)\n",
        "    return dataloader, tensors\n",
        "\n",
        "def make_tensor_dataloader(dataset, spk_field, hospk_field, align_field, align_window,\n",
        "                    trial_split, align_field_fwd, align_window_fwd):\n",
        "\n",
        "    # TODO: Complete the missing sections of this code\n",
        "    # Inputs: dataset-      The NWB dataset (not the trialized format) that will be the source of the training/validation data\n",
        "    #         spk_field-    A string that represents the field of \"heldin\" spikes, in this case \"spikes\"\n",
        "    #         hospk_field-  A string containing the field of \"heldout\" spikes, in this case \"heldout_spikes\"\n",
        "    #         align_field-  A string containing the field on which the trials should be aligned. Typically \"move_onset_time\"\n",
        "    #         align_window- A tuple of ints that designate how to cut the trials around the alignment window (in ms)\n",
        "    #         trial_split-  The trials to be used to generate the dataloader (\"train\" or \"val\")\n",
        "    # \n",
        "    # Returns: dataloader-  DataLoader object containing a 3D tensor with dimension B x T x N, where B is the number of trials, T is the trial length, and N is the number of neurons\n",
        "    #          dataset-     List containing 3 Tensor objects, the heldin spiking, the reconstructed spiking, and the velocity.\n",
        "\n",
        "    split_to_mask = lambda x: (dataset.trial_info.split == x) if isinstance(x, str) else x\n",
        "    trial_mask = split_to_mask(trial_split)\n",
        "    allow_nans = trial_split != \"train\"\n",
        "    trial_data = dataset.make_trial_data(ignored_trials=~trial_mask, allow_nans=allow_nans, align_field = align_field, align_range = align_window)\n",
        "    trial_data = add_conds_to_trial_data(trial_data, dataset)\n",
        "\n",
        "    trial_data_fwd = dataset.make_trial_data(ignored_trials=~trial_mask, allow_nans=allow_nans, align_field = align_field_fwd, align_range = align_window_fwd)\n",
        "    trial_data_fwd = add_conds_to_trial_data(trial_data_fwd, dataset)\n",
        "\n",
        "    grouped = list(trial_data.groupby('trial_id', sort=False))\n",
        "    grouped_fwd = list(trial_data_fwd.groupby('trial_id', sort=False))\n",
        "\n",
        "    # ---------------------For the students -----------------------------------\n",
        "    # These lines should pull the required spiking data from the trial_data structure\n",
        "    heldin = torch.Tensor(np.stack([trial[spk_field].to_numpy() for _, trial in grouped]))\n",
        "    heldout = torch.Tensor(np.stack([trial[hospk_field].to_numpy() for _, trial in grouped]))\n",
        "    heldin_fwd = torch.Tensor(np.stack([trial[spk_field].to_numpy() for _, trial in grouped_fwd]))\n",
        "    heldout_fwd = torch.Tensor(np.stack([trial[hospk_field].to_numpy() for _, trial in grouped_fwd]))\n",
        "    vel= torch.Tensor(np.stack([trial[\"hand_vel\"].to_numpy() for _, trial in grouped]))\n",
        "    conds = torch.Tensor(np.stack([trial[\"trial_cond\"].to_numpy() for _, trial in grouped]))\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "\n",
        "    print(f\"Shape of heldin tensor {heldin.shape}.\")\n",
        "    print(f\"Shape of heldout tensor {heldout.shape}.\")\n",
        "    print(f\"Shape of heldin tensor fwd {heldin_fwd.shape}.\")\n",
        "    print(f\"Shape of heldout tensor fwd {heldout_fwd.shape}.\")\n",
        "\n",
        "    # ---------------------For the students ----------------------------------- \n",
        "    heldin_full = torch.cat([heldin, heldin_fwd], dim=1)\n",
        "    heldout_full = torch.cat([heldout, heldout_fwd], dim = 1)\n",
        "    recon_data = torch.cat([heldin_full, heldout_full], dim =2)\n",
        "    # --------------------------------------------------------------------------\n",
        "\n",
        "    print(f\"Shape of recon tensor {recon_data.shape}.\")\n",
        "    print(f\"Shape of vel tensor {vel.shape}.\")\n",
        "\n",
        "    tensors = [heldin, recon_data, vel, conds]\n",
        "    tensor_dataset = TensorDataset(heldin, recon_data, vel, conds)\n",
        "    dataloader = DataLoader(tensor_dataset,\n",
        "                                    batch_size = 25,\n",
        "                                    num_workers = 4,\n",
        "                                    shuffle = True)\n",
        "    return dataloader, tensors\n",
        "\n",
        "\n",
        "    \n",
        "print(\"+++++++++++++++++Array Train+++++++++++++++++++\")\n",
        "dl_array_train, ds_array_train = make_array_dataloader(dataset, spk_field = \"spikes\", hospk_field=\"heldout_spikes\", \n",
        "                                    align_field = \"move_onset_time\", align_window= (-250, 450),\n",
        "                                    trial_split= \"train\")\n",
        "\n",
        "print(\"+++++++++++++++++Array Eval+++++++++++++++++++\")\n",
        "dl_array_eval, ds_array_eval =  make_array_dataloader(dataset, spk_field = \"spikes\", hospk_field=\"heldout_spikes\", \n",
        "                                    align_field = \"move_onset_time\", align_window= (-250, 450),\n",
        "                                    trial_split= \"val\")\n",
        "\n",
        "print(\"+++++++++++++++Tensor Train++++++++++++++++++++\")\n",
        "dl_tensor_train, ds_tensor_train = make_tensor_dataloader(dataset, spk_field = \"spikes\", hospk_field=\"heldout_spikes\", \n",
        "                                    align_field = \"move_onset_time\", align_window= (-250, 450),\n",
        "                                    align_field_fwd= \"move_onset_time\", align_window_fwd= (450,650),\n",
        "                                    trial_split= \"train\")\n",
        "                                    \n",
        "print(\"++++++++++++++++Tensor Eval++++++++++++++++++++\")\n",
        "dl_tensor_eval, ds_tensor_eval = make_tensor_dataloader(dataset, spk_field = \"spikes\", hospk_field=\"heldout_spikes\", \n",
        "                                    align_field = \"move_onset_time\", align_window= (-250, 450),\n",
        "                                    align_field_fwd= \"move_onset_time\", align_window_fwd= (450,650),\n",
        "                                    trial_split= \"val\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code should return:\n",
        "<blockquote>\n",
        "+++++++++++++++++Array Train+++++++++++++++++++<br>\n",
        "Shape of heldin array torch.Size([10500, 107]).<br>\n",
        "Shape of heldout array torch.Size([10500, 35]).<br>\n",
        "Shape of vel array torch.Size([10500, 2]).<br>\n",
        "+++++++++++++++++Array Eval+++++++++++++++++++<br>\n",
        "Shape of heldin array torch.Size([3500, 107]).<br>\n",
        "Shape of heldout array torch.Size([3500, 35]).<br>\n",
        "Shape of vel array torch.Size([3500, 2]).<br>\n",
        "+++++++++++++++Tensor Train++++++++++++++++++++<br>\n",
        "Shape of heldin tensor torch.Size([75, 140, 107]).<br>\n",
        "Shape of heldout tensor torch.Size([75, 140, 35]).<br>\n",
        "Shape of heldin tensor fwd torch.Size([75, 40, 107]).<br>\n",
        "Shape of heldout tensor fwd torch.Size([75, 40, 35]).<br>\n",
        "Shape of recon tensor torch.Size([75, 180, 142]).<br>\n",
        "Shape of vel tensor torch.Size([75, 140, 2]).<br>\n",
        "+++++++++++++++Tensor Eval++++++++++++++++++++<br>\n",
        "Shape of heldin tensor torch.Size([25, 140, 107]).<br>\n",
        "Shape of heldout tensor torch.Size([25, 140, 35]).<br>\n",
        "Shape of heldin tensor fwd torch.Size([25, 40, 107]).<br>\n",
        "Shape of heldout tensor fwd torch.Size([25, 40, 35]).<br>\n",
        "Shape of recon tensor torch.Size([25, 180, 142]).<br>\n",
        "Shape of vel tensor torch.Size([25, 140, 2]).<br>\n",
        "\n",
        "</blockquote>\n",
        "\n",
        "Overall:\n",
        "- 75 training trials\n",
        "- 25 eval trials\n",
        "- 140 time points (without forward pred)\n",
        "- 180 time points (forward pred)\n",
        "- 107 input neurons\n",
        "- 142 output neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**With these dataloaders, we can begin to model the neural activity!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJHhUxHH8856"
      },
      "source": [
        "# Part 2: Vanilla Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First things first: how well can we model these data with a simple nonlinear autoencoder?<br>\n",
        "You should remember this from last Friday, but as a refresher:\n",
        "\n",
        "Autoencoders are models that attempt to denoise data by compressing it through an informational bottleneck.\n",
        "\n",
        "These models typically have two components:\n",
        "- **Encoders**, which receive the high-D input data and project it down to a low-D representation (the \"latent space\").\n",
        "- **Decoders**, which take this low-D representation and attempt to regenerate the high-D input data.\n",
        "\n",
        "Because the latent space is much smaller than the data space, pushing data through an autoencoder can denoise the input signals.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/ae.png)\n",
        "https://www.compthree.com/blog/autoencoder/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For our autoencoder, we will be using a multi-layer neural network, and training the weights of this network via backpropagation of gradients.\n",
        "\n",
        "I've provided a skeleton for an autoencoder network below. The encoder and decoder each have two layers of different sizes.\n",
        "\n",
        "**Fill out the missing code to construct an autoencoder with the requirements in the description.**\n",
        "\n",
        "Note that for this model, we are not doing any forward predictions, as simple autoencoders don't model any relationship of the data in time.\n",
        "In other words, each sample is treated as independent from all other samples. This means that this model won't capture any dynamics that I explained in the introduction.\n",
        "\n",
        "(Also, this model isn't *technically* an autoencoder, because we are asking the decoder to predict the activity of neurons that the encoder did not see. For simplicity, I am going to call it an autoencoder anyway.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6JGdI0WqNj1"
      },
      "outputs": [],
      "source": [
        "# Vanilla AE code\n",
        "\n",
        "class VanillaAE(torch.nn.Module):\n",
        "  # TODO: Complete the autoencoder model\n",
        "  # Encoder requirements: \n",
        "  #   - ReLU activation functions (look in torch.nn for guidance)\n",
        "  #   - Input size = n_neurons_in\n",
        "  #   - Hidden layer sizes : 64, 16 (two hidden layers)\n",
        "  #   - Output size: latent_dim\n",
        "  # Decoder requirements:\n",
        "  #   - Input size = latent_dim\n",
        "  #   - Hidden layer sizes : 16, 64\n",
        "  #   - Output size: n_neurons_out\n",
        "\n",
        "    def __init__(self, n_neurons_in, n_neurons_out, latent_dim):\n",
        "        super().__init__()\n",
        "          \n",
        "        self.n_neurons_in = n_neurons_in\n",
        "        self.n_neurons_out = n_neurons_out\n",
        "        self.latent_dim = latent_dim\n",
        "        #----------------For Students-----------------------\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.n_neurons_in, 64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(64, 16),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(16, self.latent_dim)\n",
        "        )\n",
        "          \n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.latent_dim, 16),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(16, 64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(64, self.n_neurons_out),\n",
        "        )\n",
        "        #----------------------------------------------------\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Implement forward pass of AE network. \n",
        "        # Be sure to return both the predictions and the latent activity.\n",
        "        # Remember that the autoencoder is predicting the log-rates, so you have to\n",
        "        # transform the output of the decoder to the correct domain (0,inf)\n",
        "        # Hint: Look at Poisson GLM Link functions.\n",
        "        #----------------For Students-----------------------\n",
        "        latents = self.encoder(x)\n",
        "        rates = torch.exp(self.decoder(latents))\n",
        "        return rates, latents\n",
        "        #----------------------------------------------------\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5fbbr4e9F_t"
      },
      "source": [
        "## Prepare to train your autoencoder\n",
        "Now that you've got an autoencoder model, it's time to train it.\n",
        "The first thing that we need to do is instantiate our model, our optimizer, and our loss function.\n",
        "\n",
        "Our loss function is what we are using to calculate the \"performance\" of the network; in this case, our loss function should measure how well the autoencoder can regenerate the neural activity after passing it through a bottleneck.\n",
        "\n",
        "In general, while loss functions can be very complex, they are all required to be *differentiable*. This means that you must be able to take the derivative of the loss with respect to the weights of the neural network. Differentiability is a requirement for using the backpropagation algorithm to train a neural network!\n",
        "\n",
        "One common loss function is known as the Mean-Square-Error (MSE) loss, which takes the mean squared difference between the prediction and the target (see equation below). Linear regression minimizes MSE to fit training data.\n",
        "\n",
        "Take 5 minutes or so to talk amongst yourselves about what loss functions we might use to train our model.\n",
        "\n",
        "- What are the statistical properties of our neural spiking data?\n",
        "- What are the assumptions that we make when we use an MSE loss function?\n",
        "- Are there any loss functions that would be a better fit (pun intended) for our data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/mseLoss.png)\n",
        "https://datascience.stackexchange.com/questions/111296/how-to-calculate-loss-function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following section of code, I've provided the bones of a training loop that takes in batches of training data from our 2D training dataloader, feeds it to the model, and updates the weights of the AE to minimize the loss function.\n",
        "\n",
        "But before we get to training, we have to instantiate and pick a loss function for our model.\n",
        "\n",
        "First complete the model setup at the top of the code block, then finish the training loop below.\n",
        "\n",
        "We also want to evaluate our model occasionally on the validation dataset, but don't use that data to train the model.\n",
        "\n",
        "**Remember that testing on data used to train the model can result in overfitting!**\n",
        "\n",
        "Complete the blank sections of the code below to allow us to instantiate our model, run the training loop, and log the training and validation losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup your optimizers and run your training loop\n",
        "# Remember: we are feed in only the held-in neurons and predicting the held-out neurons\n",
        "\n",
        "latent_dim = 20\n",
        "epochs = 100\n",
        "\n",
        "outputs = []\n",
        "losses = []\n",
        "eval_losses = []\n",
        "\n",
        "# For our optimizer, we will use ADAM (an optimizer with momentum)\n",
        "# Use a learning rate of 1e-3 and a weight decay of 0.\n",
        "#----------------For Students-----------------------\n",
        "# Instantiate the VanillaAE model\n",
        "model = VanillaAE(n_neurons_in = 107, n_neurons_out=142, latent_dim = latent_dim)\n",
        "\n",
        "# Pick a loss function (HINT: Look in torch.nn.functional for some candidates!)\n",
        "loss_function = F.poisson_nll_loss\n",
        "\n",
        "# Instantiate your ADAM optimizer. You will have to pass the model's parameters (i.e., the weights of the neural network) to it\n",
        "# HINT: See if you can find a function in nn.Module that can help \n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr = 1e-3,\n",
        "                             weight_decay = 0)\n",
        "#----------------------------------------------------\n",
        "\n",
        "# This is where our training loop starts.\n",
        "# First, we iterate through epochs.\n",
        "for epoch in range(epochs):\n",
        "  # if the epoch is even, we should compute a validation loss\n",
        "  if np.mod(epoch, 2)==0:\n",
        "    epoch_eval_loss = []\n",
        "    print(\"Epoch: {}\".format(epoch))\n",
        "    model.eval() # We need to tell the model that we are in Eval mode, rather than training mode\n",
        "    #------------------For Students------------------------\n",
        "    for (eval_batch, eval_recon, eval_vel, eval_conds) in dl_array_eval:\n",
        "      reconstructed, latents = model(eval_batch)\n",
        "      eval_loss = loss_function(reconstructed, eval_recon, log_input=False)\n",
        "    #------------------------------------------------------\n",
        "      eval_losses.append([epoch, eval_loss.detach().numpy()])\n",
        "      epoch_eval_loss.append(eval_loss.detach().numpy())\n",
        "\n",
        "    print(f\"Validation Loss: {np.mean(epoch_eval_loss):0.5f}\")\n",
        "  for (data_batch, data_recon, vel_ds, train_conds) in dl_array_train:\n",
        "    model.train()\n",
        "    #------------------For Students------------------------\n",
        "    # Output of Autoencoder\n",
        "    reconstructed, latents = model(data_batch)\n",
        "    # Calculating the loss function\n",
        "    loss = loss_function(reconstructed, data_recon, log_input=False)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #-----------------------------------------------------\n",
        "    # Storing the losses in a list for plotting\n",
        "    losses.append([epoch, loss.detach().numpy()])\n",
        "\n",
        "      #------------------------------------------------------\n",
        "  outputs.append((epochs, data_batch, reconstructed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How's the model doing?\n",
        "Now we can look to see how well the vanilla autoencoder models our data. First we are going to just look at the loss.\n",
        "\n",
        "How many epochs seem to be sufficient to train this model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "NyGKEAC6rUyQ",
        "outputId": "d79f049a-b20e-4be0-ab20-9aaf4b4e943c"
      },
      "outputs": [],
      "source": [
        "losses_arr = np.array(losses)\n",
        "eval_losses_arr = np.array(eval_losses)\n",
        "\n",
        "# Defining the Plot Style\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "  \n",
        "# Plotting the last 100 values\n",
        "plt.scatter(losses_arr[:,0], losses_arr[:,1], label = \"train\")\n",
        "plt.scatter(eval_losses_arr[:,0],eval_losses_arr[:,1], label = \"eval\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxoUtaXS9Oht"
      },
      "source": [
        "## From neural firing to latent variables to neural firing\n",
        "\n",
        "As a reminder, we've trained a model to compress high-D neural activity through a small latent bottle neck, then decode those latents to reproduce the original neural activity.\n",
        "\n",
        "Let's inspect our trained model to see what this process looks like. We'll walk through the autoencoder step-by-step:\n",
        "- The firing rates that we feed into the model\n",
        "- The latent trajectories\n",
        "- The decoded firing rates at the output\n",
        "\n",
        "### Latent Trajectories\n",
        "We've already inspected the firing rates that we've fed into the model, so we'll start with the latent space.\n",
        "\n",
        "We call these low-D representations **Latent Variables** or **Neural Latents**.\n",
        "\n",
        "We can use PCA to reduce our 20D latent state to 3D so that we can visualize how the data behaves in this low-D representation:\n",
        "\n",
        "I've provided a function that will help you inspect these data\n",
        "- plot_cond_avg_latent_traj: Plots the condition-averaged or raw latent trajectories for an input list of conditions, smoothed according to an input kernel size.\n",
        "\n",
        "**Play around with plotting different conditions, kernel sizes, and whether or not to condition average the trials.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "U8K4ojfQqe_J",
        "outputId": "8d32f122-090e-4b5c-c829-e99c1fae3874"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Run the data through the model to get latent states for every trial\n",
        "pred_rates, latents = model(ds_array_train[0])\n",
        "conds = ds_array_train[3]\n",
        "\n",
        "# Get data ready for plotting\n",
        "latents_plot = torch.clone(latents)\n",
        "latents_plot = latents_plot.detach().numpy()\n",
        "conds_mat = np.reshape(conds, (75, 140))\n",
        "conds_arr = conds_mat[:,0]\n",
        "\n",
        "# Parameters to change\n",
        "# conds_to_plot is the list of conditions that the function should produce trajectories for\n",
        "conds_to_plot= [6,7,8,9]\n",
        "kernel_size =  20\n",
        "\n",
        "\n",
        "cond_avg = True # whether the single trials or condition average should be plotted\n",
        "\n",
        "plot_cond_avg_latent_traj(latents_plot=latents_plot, conds_trial=conds_arr, conds_to_plot= conds_to_plot, kernel_size=kernel_size, cond_avg= cond_avg)\n",
        "\n",
        "cond_avg = False\n",
        "plot_cond_avg_latent_traj(latents_plot=latents_plot, conds_trial=conds_arr, conds_to_plot= conds_to_plot, kernel_size=kernel_size, cond_avg= cond_avg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are a few things that you should note in these plots:\n",
        "- The latent trajectories have some temporal structure\n",
        "- The single-trial trajectories are more similar to the other trials in the same condition than trials from other conditions\n",
        "- The data are still quite noisy!\n",
        "\n",
        "### Reconstructed firing rates\n",
        "\n",
        "Now we will look at the decoder performance: **how well is our model reconstructing the input data from these latent trajectories?**\n",
        "\n",
        "I've provided another plotting function that generates plots of predicted and actual firing rates.\n",
        "\n",
        "Play around with these plots and answer these questions:\n",
        "- How well is the model doing? (qualitatively)\n",
        "- Which neurons are being predicted well?\n",
        "- Which neurons are being predicted poorly?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pass data through the model\n",
        "spiking = torch.clone(ds_array_train[0])\n",
        "spiking = spiking.detach().numpy()\n",
        "pred_rates_plot = torch.clone(pred_rates)\n",
        "pred_rates_plot = pred_rates_plot.detach().numpy()\n",
        "\n",
        "# Plotting params\n",
        "window = np.array([0, 2000]) # the sample window to plot\n",
        "kernel_size = 10 # kernel size\n",
        "\n",
        "# Iterate through and plot the first 20 neurons\n",
        "for i in range(20): \n",
        "    plotPredictedFR(pred_rates_plot, spiking, unitNum= i, kernel_size=kernel_size, window = window)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The AE seems to be doing a decent job a capturing the firing rates of the neurons:\n",
        "\n",
        "However, we can see that there are some neurons where the model has very poor decoding from the latent state.\n",
        "\n",
        "Remember that even though we optimize our auto-encoder to maximize reconstruction accuracy that isn't our goal (otherwise, why would we pass the data through a bottleneck at all?). \n",
        "\n",
        "We have other data that we can use to quantify how well our model is doing.\n",
        "\n",
        "**We are now going to test the ability of our model to decode hand velocity and capture the firing rates of the held-out neurons**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the smoothing size\n",
        "kernel_size = 15\n",
        "\n",
        "computeHandVelR2(model, ds_array_train= ds_array_train, kernel_size_in= kernel_size, gaussian = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take a few minutes to play around the smoothing width and observe its effect on the velocity and heldout spiking predictions.\n",
        "- Why might the models that decode from the latents perform so much worse?\n",
        "- What's the best velocity decoding performance that you can get?\n",
        "- What's the best held-out spiking decoding performance you can get?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2iBMAUL68iu"
      },
      "source": [
        "# Part 3: Sequential Auto-Encoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOlgCwAz7CbP"
      },
      "source": [
        "## Why Neural Dynamics are important:\n",
        "As seen above, there is often a temporal structure to the firing behavior of a population of neurons\n",
        "\n",
        "\n",
        "Models that can capture that temporal structure may allow us to denoise neural data more effectively than methods that do not take them into account (like the AE above).\n",
        "\n",
        "\n",
        "**As Jonathan will discuss on Friday, these dynamics might also tell us important information about the neural circuit itself!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/image2.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What is a dynamical system?\n",
        "\n",
        "A dynamical system is a system whose state develops over time as a function of its current state and inputs.\n",
        "\n",
        "Formally, discrete-time dynamical systems can be described by the equation:\n",
        "\n",
        "$x_{t+1} = f(x_{t}, u_{t})$ \n",
        "\n",
        "where $x$ represents a set of state variables for the system, $u$ represents inputs to the system and $f$ represents a function that relates the current state and inputs to the subsequent state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The equation $x_{t+1} = f(x_{t}, u_{t})$ is the most general form of a discrete-time dynamical system. The function $f$ can represent any number of highly complex nonlinear relationships between the current and subsequent states.\n",
        "\n",
        "If we make some assumptions about system, we can simplify these equations dramatically.\n",
        "\n",
        "First, if the dynamics are linear we can transform\n",
        "\n",
        " $x_{t+1} = f(x_{t}, u_{t})$ \n",
        " \n",
        " into\n",
        " \n",
        " $x_{t+1} = Ax_{t} + Bu_{t}$ \n",
        "\n",
        " Second, if we assume no inputs then the dynamics become\n",
        "\n",
        " $x_{t+1} = Ax_{t}$\n",
        "\n",
        " As we can see, these dynamics can be reduced to a set of repeated multiplications by the same matrix A.\n",
        "\n",
        " A dynamical system with no inputs is said to be **autonomous**, meaning that all of the movements of the state are the result of dynamics that originate within the system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recurrent Neural Networks:\n",
        "\n",
        "Recurrent neural networks (RNNs) add to a standard neural network a \"state\" that can keep track of previous inputs.\n",
        "\n",
        "A major motivation for RNNs comes from domains in which the data can be viewed as the product of a serial process, like language.\n",
        "\n",
        "\n",
        "As an example, consider the following sentence:\n",
        "\n",
        "> The quick brown fox jumped over the lazy ___\n",
        "\n",
        "When we read this sentence, our \"guess\" for what the missing word is incorporates information from the preceding words.\n",
        "\n",
        "**Importantly, the order of the words matters for the meaning of the sentence!**\n",
        "\n",
        "> I gave the book to Jim\n",
        "\n",
        "has a very different meaning than\n",
        "\n",
        "> I gave Jim to the book"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RNNs use a \"hidden state\" to capture the sequential relationship of these types of data. Each RNN cell stores a value that encodes some representation of the inputs that the cell had seen previously. \n",
        "\n",
        "**In this way, the RNN has a \"memory\" of it's past inputs.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Relating Dynamics and Recurrent Neural Networks:\n",
        "\n",
        "Now that you understand what \"dynamics\" are and the basic principles behind RNNs, we can begin to look at how we might use RNNs to denoise neural data.\n",
        "\n",
        "We are going to start with a very simple form of the RNN, a \"Linear\" RNN. An example is shown in the figure below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/RNN3Fold.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inside the each RNN unit is a state variable $h$. The state variable $h$ acts recurrently on itself with the matrix $A$ and is affected by $u$ through the matrix $B$.\n",
        "\n",
        "Matrices $A$ and $B$ are parameters of a neural network that can be trained via gradient descent.\n",
        "\n",
        "At each time step, $h$ is updated as a function of $h$ and $u$ through $A$ and $B$. We can unroll this network over time to look at it more closely."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/RNN3UnFold.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seem familiar?\n",
        "\n",
        "The RNN update equations\n",
        "\n",
        "$h_{t+1} = Ah_{t} + Bu_{t}$\n",
        "\n",
        "are able to model linear dynamical system of the form\n",
        "\n",
        "$x_{t+1} = Ax_{t} + Bu_{t}$\n",
        "\n",
        "simply by learning the A and B matrices via backpropagation!\n",
        "\n",
        "There are many different types of RNNs, but their major differences arise in precisely how the next state is computed using the previous state and inputs. For instance, linear RNNs use a linear combination of the input and hidden state at time t to update the state at t+1. \n",
        "\n",
        "**Because Linear RNNs model the dynamics with a matrix $A$, they can only capture systems with linear dynamics**\n",
        "\n",
        "I have provided some code below that you can use to find what sorts of systems can be captured by linear dynamics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Some example A matrices and their behavior when used to simulate a dynamical system\n",
        "# Feed these matrices into the simulate_system function to visualize the sorts of behavior that different A matrices can produce.\n",
        "# you can also try some out for yourself!\n",
        "\n",
        "fast_slow_attractor = np.array([[.5, -.4], [-.4, .5]]) \n",
        "node = np.array([[0.95, 0], [0, .95]])\n",
        "spiral_repulsor = np.array([[.99, -1], [1, .99]])\n",
        "\n",
        "simulate_system(fast_slow_attractor, n_inits=100, n_steps =20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How about the system from the introduction? Can we simulate these neural dynamics in the same way?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/Dyn1.png)\n",
        "![title](../../images/Dyn2.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "circle_neurons = np.array([[0,1,0],[0,0,1],[1,0,0]])\n",
        "\n",
        "init_state = np.array([0.5,0,0])\n",
        "\n",
        "simulate_3D_system(circle_neurons, init_state, 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note two very important things about these simulations:\n",
        "- The intial conditions (green dots) determine precisely how the state will develop (because the dynamics are autonomous)\n",
        "- Different regions have different dynamics (i.e., where you are determines where you will go)\n",
        "\n",
        "**Therefore, any model of neural dynamics will need to perform two critical tasks:**\n",
        "1. **Estimate initial conditions**\n",
        "2. **Model the dynamics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sequential Auto-Encoder Model\n",
        "\n",
        "Now we will start to write the code that will allow us to model the dynamics of the motor cortex during the reaching task we worked with above!\n",
        "\n",
        "**The diagram below shows the two most important components of a state-of-the-art latent variable model known as Latent Factor Analysis via Dynamical Systems (LFADS)**\n",
        "- Encoder: Transforms spiking activity into a set of initial conditions (g0) of a dynamical system\n",
        "- Decoder/Generator: Simulates the development of a dynamical system over time g(t).\n",
        "\n",
        "This model is known as a **Sequential Auto-Encoder**, because it *encodes* the neural activity into an initial condition in a low-D latent space, then *decodes* the activity with a dynamics model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/LFADS_architecture.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LFADS is trained to reduce the error between the predicted n(t) and the \"true\" n(t). It uses an encoder to find initial conditions and a Generator that models the latent dynamics of the circuit.\n",
        "\n",
        "**Importantly, the dynamics model $g(t)$ is lower dimensional than the neural activity $n(t)$**\n",
        "\n",
        "**This means that the dynamics are not unfolding in the \"neural space\", but in a lower dimensional \"latent space\" (analogous to the hidden layer of our AE network)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Steps to get to LFADS:\n",
        "\n",
        "1. **Estimate initial conditions as simply as possible**\n",
        "2. **Model dynamics with linear RNN**\n",
        "3. **Model dynamics with Gated recurrent unit (GRU) RNN**\n",
        "4. **Estimate initial conditions using GRU**\n",
        "5. Variational Training\n",
        "6. Non-autonomous dynamics\n",
        "\n",
        "We will only get to step 4 today, but there is code available online for you to run the full LFADS model on these data if you are interested!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Estimate initial conditions as simply as possible:\n",
        "\n",
        "We are going to need to find initial conditions if we want our sequential auto-encoder model to work.\n",
        "\n",
        "We are eventually going to use an RNN to do this too, but for now let's just use the simplest model at our disposal: simple linear regression.\n",
        "\n",
        "We're going to take the whole trial worth of firing data and feed it all to a linear model that will predict initial conditions for our RNNs.\n",
        "\n",
        "The dimensions of this linear model will be:\n",
        "- input: Heldin_neurons x num_bins\n",
        "- output: hidden size\n",
        "\n",
        "Complete the LinearEncoder class below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LinearEncoder(nn.Module):\n",
        "  def __init__(self, input_size,trial_len, hidden_size):\n",
        "    super().__init__()\n",
        "    # TODO: Complete the init function\n",
        "    #---------------Student's work------------------------------------------\n",
        "    self.input_size = input_size\n",
        "    self.trial_len = trial_len\n",
        "    self.hidden_size = hidden_size\n",
        "    self.encoder = nn.Linear(input_size*trial_len, hidden_size)\n",
        "    #-----------------------------------------------------------------------\n",
        "  def forward(self, input):\n",
        "    # print(\"run forward)\")\n",
        "    # TODO: Complete the forward pass for the LinearEncoder\n",
        "    n_trials, n_time, n_neurons = input.shape\n",
        "    # print(input.shape)\n",
        "    input = torch.reshape(input, (n_trials, -1))\n",
        "    ics =self.encoder(input)\n",
        "    return ics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Linear RNN to model dynamics\n",
        "\n",
        "Linear RNNs are very simple to code and understand, but can't capture complex systems as well as GRUs. You will learn to code both RNN cells in this tutorial, starting with the Linear RNN below.\n",
        "\n",
        "As described above, Linear RNN cells only use linear weights to govern the state update.\n",
        "\n",
        "Mathematically:\n",
        "\n",
        ">hidden(t+1) = whh * hidden(t) + wih * hidden(t)\n",
        "\n",
        "Think how this could be accomplished with a single nn.Linear layer\n",
        "\n",
        "\n",
        "\n",
        "For this block, each forward pass will receive its hidden state and one time step of input as arguments. The class should perform a single state update each time its forward method is called. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "class LinearRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    # TODO: Complete the init function\n",
        "    # Set instance variables\n",
        "    # Initialize the hidden state to zeros\n",
        "    # Initialize a linear network to update the hidden state using the input and the previous hidden state\n",
        "    #---------------Student's work------------------------------------------\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.in2hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    #-----------------------------------------------------------------------\n",
        "  def forward(self, input, hidden):\n",
        "    # TODO: Complete the forward pass for the Linear RNN\n",
        "    # Stack the inputs and hidden states\n",
        "    # Pass them through the linear network to update the hidden state\n",
        "    combined = torch.cat((input, hidden),1)\n",
        "    hidden =self.in2hidden(combined)\n",
        "    return hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that you have a simple Linear RNN cell that performs the state update, we will wrap this class with an Abstract RNN that we will be able to re-use for all of the other RNN cells that we code.\n",
        "\n",
        "\n",
        "You'll need to complete the forward pass of this network. In the forward pass, the RNN should recurrently update its hidden state by calling its \"cell\" object. This cell will be the Linear RNN that you coded above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_function = F.poisson_nll_loss\n",
        "class AbstractRNN(nn.Module):\n",
        "  def __init__(self, cell, fwd_steps):\n",
        "    super().__init__()\n",
        "    self.cell = cell\n",
        "    self.fwd_steps = fwd_steps\n",
        "\n",
        "  def forward(self,input, h_0):\n",
        "    hidden = h_0\n",
        "    n_batch, n_time, n_inputs = input.shape\n",
        "    #---------------------Student's Work--------------------------------------------\n",
        "    states = torch.zeros(n_batch, n_time, self.cell.hidden_size)\n",
        "    for i, input_step in enumerate(input.transpose(0,1)):\n",
        "      # print(input_step.shape)\n",
        "      hidden = self.cell(input_step, hidden)\n",
        "      states[:, i,:] = hidden\n",
        "    #---------------------------------------------------------------------------\n",
        "    return states, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have a fully-functional RNN cell, let's see how well it works on the neural data.\n",
        "\n",
        "We'll use a relatively simple version of an architecture called a Sequential Auto-Encoder (SAE). It is called this because its job is to reproduce the input data (the same as the vanilla auto-encoder above), excpet it models the sequential structure of the data. \n",
        "\n",
        "**While the vanilla Auto-Encoder treats each sample as independent from every other sample, SAEs require data that maintains the temporal relationship between samples.**\n",
        "\n",
        "*Luckily, the tensor dataloaders we made above do exactly that!*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first SAE model that we will code is trained to predict the next time step of neural activity from the current input and the hidden state.\n",
        "\n",
        "**By learning the mapping from the neural activity at time t and the hidden state to the activity at t+1, the SAE captures the dynamics of the data (i.e., how it develops over time).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vanilla SAE code\n",
        "class VanillaSAE(torch.nn.Module):\n",
        "    def __init__(self, \n",
        "                input_size = 107, \n",
        "                latent_size = 40, \n",
        "                out_size = 142,\n",
        "                encoder = None, \n",
        "                decoder_cell = None, \n",
        "                fwd_steps = 40):\n",
        "        super().__init__()\n",
        "        #---------------Student's work------------------------------------------\n",
        "        self.encoder = encoder\n",
        "        self.fwd_steps = fwd_steps\n",
        "        self.decoder = AbstractRNN(decoder_cell(input_size=1, hidden_size=latent_size), fwd_steps=fwd_steps)\n",
        "        self.readout = nn.Linear(latent_size, out_size)\n",
        "        #----------------------------------------------------------------------\n",
        "  \n",
        "    def forward(self, x):\n",
        "        # Implement forward pass of AE network\n",
        "        #---------------Student's work------------------------------------------\n",
        "        # print(f\"input shape {x.shape}\")\n",
        "        n_batch, n_time, n_heldin = x.shape\n",
        "        input_fwd = torch.zeros((n_batch, n_time + self.fwd_steps, 1))\n",
        "        ics = self.encoder(x)\n",
        "        latents_rnn, hidden = self.decoder(input_fwd,ics)\n",
        "        # print(f\"RNN states shape {latents_rnn.shape}\")\n",
        "        log_rates = self.readout(latents_rnn)\n",
        "        # print(f\"latents {latents.shape}\")\n",
        "        rates = torch.exp(log_rates)\n",
        "        # print(f\"logRates shape {log_rates.shape}\")\n",
        "        #----------------------------------------------------------------------\n",
        "        return rates, latents_rnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I know that I've already made you write one training loop, but this is good practice!\n",
        "\n",
        "**Think about how the data should be fed into the models.**\n",
        "- What should the dimensionality be?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_function = F.poisson_nll_loss\n",
        "# Build your training loop\n",
        "epochs = 100\n",
        "outputs = []\n",
        "\n",
        "lin_rnn = VanillaSAE(input_size = 107, latent_size = 40, out_size = 142, encoder = LinearEncoder(107, 140, 40), decoder_cell = LinearRNN)\n",
        "losses = np.zeros(epochs)\n",
        "print(f\"Working on GRU model:\")\n",
        "optimizer = torch.optim.Adam(lin_rnn.parameters(),\n",
        "                            lr = 1e-3,\n",
        "                            weight_decay = 1e-8)\n",
        "eval_losses = []\n",
        "for epoch in range(epochs):\n",
        "    if np.mod(epoch, 10)==0:\n",
        "        epoch_eval_loss = []\n",
        "        print(\"Epoch: {}\".format(epoch))\n",
        "        lin_rnn.eval() # We need to tell the model that we are in Eval mode, rather than training mode\n",
        "        #------------------For Students------------------------\n",
        "        for (eval_batch, eval_recon, eval_vel, eval_conds) in dl_tensor_eval:\n",
        "            reconstructed, latents = lin_rnn(eval_batch)\n",
        "            eval_loss = loss_function(reconstructed, eval_recon, log_input=False)\n",
        "            #------------------------------------------------------\n",
        "            eval_losses.append([epoch, eval_loss.detach().numpy()])\n",
        "            epoch_eval_loss.append(eval_loss.detach().numpy())\n",
        "        print(f\"Validation Loss: {np.mean(epoch_eval_loss):0.5f}\")\n",
        "\n",
        "    for (data_batch, data_recon, vel, train_conds) in dl_tensor_train:\n",
        "        #------------------For Students------------------------\n",
        "        # Output of Autoencoder\n",
        "        rates, latents = lin_rnn(data_batch)\n",
        "        # Calculating the loss function\n",
        "        loss = loss_function(rates, data_recon, log_input=False)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #-----------------------------------------------------\n",
        "        # Storing the losses in a list for plotting\n",
        "        losses[epoch] = loss.detach().numpy()\n",
        "\n",
        "    # outputs.append((epochs, data_batch, reconstructed))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses_arr = np.array(losses)\n",
        "eval_losses_arr = np.array(eval_losses)\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss') \n",
        "epoch = np.linspace(0,len(losses_arr), len(losses_arr))\n",
        "t = np.linspace(0, len(losses_arr),len(losses_arr))\n",
        "# Plotting the last 100 values\n",
        "plt.plot(epoch, losses_arr, label = \"train\")\n",
        "plt.scatter(eval_losses_arr[:,0],eval_losses_arr[:,1], label = \"eval\", color = 'r')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We finally have a working sequential autoencoder!\n",
        "\n",
        "Let's look to see what the latent trajectories and predicted firing rates look like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_data, recon_target, vel, conds = ds_tensor_train \n",
        "\n",
        "recon_data, latents = lin_rnn(input_data)\n",
        "ics = lin_rnn.encoder(input_data)\n",
        "ics_numpy = ics.detach().numpy()\n",
        "\n",
        "conds_arr =  conds[:,0]\n",
        "conds_to_plot = [0,1,2,3,4]\n",
        "cond_avg = False\n",
        "\n",
        "plot_ics(ics_numpy=ics_numpy, cond_arr = conds_arr)\n",
        "plot_cond_avg_latent_traj(latents_plot=latents_plot, conds_trial=conds_arr, conds_to_plot= conds_to_plot, kernel_size=kernel_size, cond_avg= cond_avg)\n",
        "\n",
        "\n",
        "computeHandVelR2Tensor(lin_rnn, ds_tensor_train, kernel_size_in=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Model dynamics using GRU RNN\n",
        "\n",
        "As we have shown above, linear RNNs have limited expressiveness; they can only model linear dynamical systems!\n",
        "\n",
        "There even making the linear RNN nonlinear leaves some major issues, which I we can talk about below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Vanishing Gradient problem\n",
        "\n",
        "\n",
        "Imagine a 1D Linear RNN: This RNN has a single scalar value that determines it's recurrent connectivity.\n",
        "\n",
        "When this RNN updates its state, you can think of it as a recurrent multiplication by a scalar. This can quickly lead to problems where the gradient \"vanishes\"\n",
        "\n",
        "This is aptly called the **Vanishing Gradient Problem**\n",
        "\n",
        "\n",
        "Take as an example a Linear RNN, with a initial hidden state of 1.0 and a recurrent weight of 0.5.\n",
        "\n",
        "If I unroll this RNN over time for just 10 steps, the state would be 1.0 * (0.5 ** 10)  which would be about equal to 0.001."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/Vanishing-Gradient-Problem.png)\n",
        "https://analyticsindiamag.com/can-relu-cause-exploding-gradients-if-applied-to-solve-vanishing-gradients/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The vanishing gradient problem can make it difficult to update the weights early in the network because the gradients can get so small!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Long-term Dependency Problem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is another related issue with these models called the **Long-Term Dependency problem**\n",
        "\n",
        "Take as an example the following text:\n",
        "> Jim and I walked to the store, saw Harry, and decided to call two Ubers to drive us to the movie theatre. I don't like Harry very much, so I got in the Uber with ___\n",
        "\n",
        "You should be able to infer from context that the correct word to insert into the blank is \"Jim\". Unfortunately, \"Jim\" was the very first word of the whole sample, meaning that if I wanted to train an RNN to perform this task, **it would need to \"remember\" Jim for two full sentences!**\n",
        "\n",
        "For the same reason as the vanishing gradient problem (recurrent multiplication will either vanish or explode) these long-term dependencies pose a major problem for Vanilla RNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/LongTermProblem.png)\n",
        "#https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cmou8RJBJIqB"
      },
      "source": [
        "#### Gated Recurrent Units solve the Vanishing gradient and long-term dependency problems\n",
        "\n",
        "GRUs are a more complex non-linear RNNs that have methods to stop the RNN from \"forgetting\" things that happened a long time ago.\n",
        "\n",
        "The exact internals of the GRU are beyond the scope of this workshop (see the diagram below), but if you want to code the GRU from scratch there are many good resources online."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![title](../../images/GRU.png)\n",
        "https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_function = F.poisson_nll_loss\n",
        "from torch.nn import GRUCell\n",
        "# Build your training loop\n",
        "epochs = 100\n",
        "outputs = []\n",
        "\n",
        "gru_rnn = VanillaSAE(input_size = 107, latent_size = 64, out_size = 142, encoder = LinearEncoder(107, 140, 64), decoder_cell = GRUCell)\n",
        "losses = np.zeros(epochs)\n",
        "print(f\"Working on GRU model:\")\n",
        "optimizer = torch.optim.Adam(gru_rnn.parameters(),\n",
        "                            lr = 1e-3,\n",
        "                            weight_decay = 1e-8)\n",
        "eval_losses = []\n",
        "for epoch in range(epochs):\n",
        "    if np.mod(epoch, 10)==0:\n",
        "        epoch_eval_loss = []\n",
        "        print(\"Epoch: {}\".format(epoch))\n",
        "        gru_rnn.eval() # We need to tell the model that we are in Eval mode, rather than training mode\n",
        "        #------------------For Students------------------------\n",
        "        for (eval_batch, eval_recon, eval_vel, asdf) in dl_tensor_eval:\n",
        "            reconstructed, latents = gru_rnn(eval_batch)\n",
        "            eval_loss = loss_function(reconstructed, eval_recon, log_input=False)\n",
        "            #------------------------------------------------------\n",
        "            eval_losses.append([epoch, eval_loss.detach().numpy()])\n",
        "            epoch_eval_loss.append(eval_loss.detach().numpy())\n",
        "        print(f\"Validation Loss: {np.mean(epoch_eval_loss):0.5f}\")\n",
        "\n",
        "    for (data_batch, data_recon, vel, asdf) in dl_tensor_train:\n",
        "        #------------------For Students------------------------\n",
        "        # Output of Autoencoder\n",
        "        rates, latents = gru_rnn(data_batch)\n",
        "        # Calculating the loss function\n",
        "        loss = loss_function(rates, data_recon, log_input=False)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #-----------------------------------------------------\n",
        "        # Storing the losses in a list for plotting\n",
        "        losses[epoch] = loss.detach().numpy()\n",
        "\n",
        "    # outputs.append((epochs, data_batch, reconstructed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses_arr = np.array(losses)\n",
        "eval_losses_arr = np.array(eval_losses)\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss') \n",
        "epoch = np.linspace(0,len(losses_arr), len(losses_arr))\n",
        "t = np.linspace(0, len(losses_arr),len(losses_arr))\n",
        "# Plotting the last 100 values\n",
        "plt.plot(epoch, losses_arr, label = \"train\")\n",
        "plt.scatter(eval_losses_arr[:,0],eval_losses_arr[:,1], label = \"eval\", color = 'r')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_data, recon_target, vel, conds = ds_tensor_train \n",
        "\n",
        "recon_data, latents = gru_rnn(input_data)\n",
        "ics = gru_rnn.encoder(input_data)\n",
        "ics_numpy = ics.detach().numpy()\n",
        "\n",
        "conds_arr =  conds[:,0]\n",
        "conds_to_plot = [0,1,2,3,4]\n",
        "cond_avg = False\n",
        "\n",
        "plot_ics(ics_numpy=ics_numpy, cond_arr = conds_arr)\n",
        "plot_cond_avg_latent_traj(latents_plot=latents_plot, conds_trial=conds_arr, conds_to_plot= conds_to_plot, kernel_size=kernel_size, cond_avg= cond_avg)\n",
        "computeHandVelR2Tensor(gru_rnn, ds_tensor_train=ds_tensor_train, kernel_size_in=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Run the training loop above to see how well the GRU models the data!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Estimation ICs using GRU network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are getting pretty close to LFADS, but our simple encoder architecture may needs some tweaking.\n",
        "\n",
        "One way that we can improve the encoders is to use GRUs instead of a simple linear regression, which will allow us to model nonlinearities in the relationship between neural firing and the initial conditions of a trial.\n",
        "\n",
        "Coding these new encoders are a little complicated, but can be broken into a few steps\n",
        "- Feed trial into encoder, output hidden state at end of encoder pass\n",
        "- Feed trial into encoder backwards (bidirectional)\n",
        "- Concatenate forward and reverse passes of GRU encoders.\n",
        "- Linearly project to hidden size of Generator network for ICs.\n",
        "\n",
        "Luckily, the GRU module in pytorch can simplify this process greatly through its \"bidirectional\" flag.\n",
        "\n",
        "Passing\n",
        "\n",
        "> bidirectional = True \n",
        "\n",
        "into the GRU network runs the encoder model backwards and forwards on the input data and returns the hidden states stacked along the last dimension of the output tensor.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vanilla SAE code\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, cell):\n",
        "        super().__init__()\n",
        "        self.cell = cell\n",
        "\n",
        "    def forward(self, input, h_0):\n",
        "        hidden = h_0\n",
        "        states = []\n",
        "        for input_step in input.transpose(0, 1):\n",
        "            hidden = self.cell(input_step, hidden)\n",
        "            states.append(hidden)\n",
        "        states = torch.stack(states, dim=1)\n",
        "        return states, hidden\n",
        "\n",
        "class GRUSAE(torch.nn.Module):\n",
        "    def __init__(self, \n",
        "                input_size = 107, \n",
        "                latent_size = 64, \n",
        "                encoder_size = 64, \n",
        "                out_size = 142, \n",
        "                cell_gen = None, \n",
        "                fwd_steps = 40):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.GRU(input_size = input_size,\n",
        "                               hidden_size = encoder_size,\n",
        "                               batch_first = True,\n",
        "                               bidirectional = True)\n",
        "        self.ic_linear = nn.Linear(2 * encoder_size, latent_size)\n",
        "        self.fwd_steps = fwd_steps\n",
        "        self.decoder =  RNN(nn.GRUCell(input_size=1, hidden_size=latent_size))\n",
        "        self.readout = nn.Linear(latent_size, out_size)\n",
        "\n",
        "  \n",
        "    def forward(self, x):\n",
        "        # Implement forward pass of AE network\n",
        "        #---------------Student's work------------------------------------------\n",
        "        _, h_n = self.encoder(x)\n",
        "        h_n = torch.cat([*h_n], -1)\n",
        "        B, T, _ = x.shape\n",
        "        ic = self.ic_linear(h_n)\n",
        "        input_placeholder = torch.zeros((B, T+self.fwd_steps, 1))\n",
        "        latents_rnn, hidden_rnn = self.decoder(input_placeholder, ic)\n",
        "        rates = torch.exp(self.readout(latents_rnn))\n",
        "        #----------------------------------------------------------------------\n",
        "        return rates, latents_rnn\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_function = F.poisson_nll_loss\n",
        "# Build your training loop\n",
        "epochs = 100\n",
        "sae = GRUSAE(input_size = 107, latent_size = 128, out_size = 142, fwd_steps= 40)\n",
        "losses = np.zeros(epochs)\n",
        "print(f\"Working on GRU model:\")\n",
        "optimizer = torch.optim.Adam(sae.parameters(),\n",
        "                            lr = 1e-3,\n",
        "                            weight_decay = 1e-8)\n",
        "eval_losses = []\n",
        "for epoch in range(epochs):\n",
        "    if np.mod(epoch, 10)==0:\n",
        "        epoch_eval_loss = []\n",
        "        print(\"Epoch: {}\".format(epoch))\n",
        "        sae.eval() # We need to tell the model that we are in Eval mode, rather than training mode\n",
        "        #------------------For Students------------------------\n",
        "        for (eval_batch, eval_recon, eval_vel, asdf) in dl_tensor_eval:\n",
        "            reconstructed, latents = sae(eval_batch)\n",
        "            eval_loss = loss_function(reconstructed, eval_recon, log_input=False)\n",
        "            #------------------------------------------------------\n",
        "            eval_losses.append([epoch, eval_loss.detach().numpy()])\n",
        "            epoch_eval_loss.append(eval_loss.detach().numpy())\n",
        "        print(f\"Validation Loss: {np.mean(epoch_eval_loss):0.5f}\")\n",
        "    for (data_batch, data_recon, vel, train_conds) in dl_tensor_train:\n",
        "\n",
        "        #------------------For Students------------------------\n",
        "        # Output of Autoencoder\n",
        "        rates, latents = sae(data_batch)\n",
        "        # Calculating the loss function\n",
        "        loss = loss_function(rates, data_recon, log_input=False)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #-----------------------------------------------------\n",
        "        # Storing the losses in a list for plotting\n",
        "        losses[epoch] = loss.detach().numpy()\n",
        "    # outputs.append((epochs, data_batch, reconstructed))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses_arr = np.array(losses)\n",
        "eval_losses_arr = np.array(eval_losses)\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss') \n",
        "epoch = np.linspace(0,len(losses_arr), len(losses_arr))\n",
        "t = np.linspace(0, len(losses_arr),len(losses_arr))\n",
        "# Plotting the last 100 values\n",
        "plt.plot(epoch, losses_arr, label = \"train\")\n",
        "plt.scatter(eval_losses_arr[:,0],eval_losses_arr[:,1], label = \"eval\", color = 'r')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_data, recon_target, vel, conds = ds_tensor_train \n",
        "\n",
        "recon_data, latents = sae(input_data)\n",
        "_, ics = sae.encoder(input_data)\n",
        "ics = torch.cat([*ics], -1)\n",
        "ic_linear = sae.ic_linear(ics)\n",
        "\n",
        "ics_numpy = ics.detach().numpy()\n",
        "\n",
        "conds_arr =  conds[:,0]\n",
        "conds_to_plot = [10,11,12,13]\n",
        "cond_avg = False\n",
        "\n",
        "plot_ics(ics_numpy=ics_numpy, cond_arr = conds_arr)\n",
        "plot_cond_avg_latent_traj(latents_plot=latents_plot, conds_trial=conds_arr, conds_to_plot= conds_to_plot, kernel_size=kernel_size, cond_avg= cond_avg)\n",
        "computeHandVelR2Tensor(sae, ds_tensor_train=ds_tensor_train, kernel_size_in=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## But these still aren't as good as the regular autoencoder!\n",
        "\n",
        "Unfortunately, real neural data can be quite messy, and there are a few tricks to get the dynamics models to fit well.\n",
        "\n",
        "So that you can get a sense of how well a \"good\" model performs, check out the code below!\n",
        "\n",
        "This was a model trained with a specialized training procedure called \"coordinated dropout\" for 10,000 epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -O pretrained_rnn.ckpt https://github.com/neurallatents/nlb_workshop/blob/main/nlb_technical/pretrained_rnn.ckpt?raw=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nlb_tools.make_tensors import make_train_input_tensors, make_eval_input_tensors\n",
        "\n",
        "curr_path = os.getcwd()\n",
        "fpath = \"../../data/000138/sub-Jenkins/\"\n",
        "os.listdir(fpath) \n",
        "\n",
        "dataset_large = NWBDataset(fpath=fpath) \n",
        "dataset_large.resample(5)\n",
        "\n",
        "train_dict = make_train_input_tensors(dataset=dataset_large, \n",
        "                                      dataset_name='mc_maze_large', \n",
        "                                      trial_split='train', # trial_split=['train', 'val'], for Test phase\n",
        "                                      save_file=False, \n",
        "                                      include_forward_pred=True)\n",
        "\n",
        "eval_dict = make_eval_input_tensors(dataset=dataset_large,\n",
        "                                    dataset_name='mc_maze_large',\n",
        "                                    trial_split='val', # trial_split='test', for Test phase\n",
        "                                    save_file=False)\n",
        "\n",
        "class NLBRNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1, dropout=0.3, device=None, dtype=None):\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super(NLBRNN, self).__init__()\n",
        "        self.dropout1 = torch.nn.Dropout(p=dropout)\n",
        "        self.rnn = torch.nn.GRU(input_size=input_dim,\n",
        "                                hidden_size=hidden_dim,\n",
        "                                num_layers=num_layers,\n",
        "                                batch_first=True,\n",
        "                                dropout=(dropout if num_layers > 1 else 0.),\n",
        "                                bidirectional=False,\n",
        "                                **factory_kwargs)\n",
        "        self.dropout2 = torch.nn.Dropout(p=dropout)\n",
        "        self.transform = torch.nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        output, hidden = self.rnn(self.dropout1(X))\n",
        "        output = self.transform(self.dropout2(output))\n",
        "        return torch.exp(output), hidden\n",
        "\n",
        "training_input = torch.Tensor(\n",
        "    np.concatenate([\n",
        "        train_dict['train_spikes_heldin'], \n",
        "        np.zeros(train_dict['train_spikes_heldin_forward'].shape), # zeroed inputs for forecasting\n",
        "    ], axis=1))\n",
        "\n",
        "training_output = torch.Tensor(\n",
        "    np.concatenate([\n",
        "        np.concatenate([\n",
        "            train_dict['train_spikes_heldin'],\n",
        "            train_dict['train_spikes_heldin_forward'],\n",
        "        ], axis=1),\n",
        "        np.concatenate([\n",
        "            train_dict['train_spikes_heldout'],\n",
        "            train_dict['train_spikes_heldout_forward'],\n",
        "        ], axis=1),\n",
        "    ], axis=2))\n",
        "\n",
        "eval_input = torch.Tensor(\n",
        "    np.concatenate([\n",
        "        eval_dict['eval_spikes_heldin'],\n",
        "        np.zeros((\n",
        "            eval_dict['eval_spikes_heldin'].shape[0],\n",
        "            train_dict['train_spikes_heldin_forward'].shape[1],\n",
        "            eval_dict['eval_spikes_heldin'].shape[2]\n",
        "        )),\n",
        "    ], axis=1))\n",
        "\n",
        "model = NLBRNN(input_dim=training_input.shape[2], hidden_dim=40, output_dim=training_output.shape[2])\n",
        "ckpt = torch.load('pretrained_rnn.ckpt')\n",
        "model.load_state_dict(ckpt['state_dict'])\n",
        "\n",
        "model.eval()\n",
        "training_predictions_torch, latents_train_torch = model(training_input)\n",
        "training_predictions = training_predictions_torch.cpu().detach().numpy()\n",
        "latents_train = latents_train_torch.cpu().detach().numpy()\n",
        "\n",
        "eval_predictions_torch, latents_val_torch  = model(eval_input)\n",
        "eval_predictions = eval_predictions_torch.cpu().detach().numpy()\n",
        "latent_val = latents_val_torch.cpu().detach().numpy()\n",
        "\n",
        "tlen = train_dict['train_spikes_heldin'].shape[1]\n",
        "num_heldin = train_dict['train_spikes_heldin'].shape[2]\n",
        "\n",
        "print(latents_train.shape)\n",
        "\n",
        "submission = {\n",
        "    'mc_maze_large': {\n",
        "        'train_rates_heldin': training_predictions[:, :tlen, :num_heldin],\n",
        "        'train_rates_heldout': training_predictions[:, :tlen, num_heldin:],\n",
        "        'eval_rates_heldin': eval_predictions[:, :tlen, :num_heldin],\n",
        "        'eval_rates_heldout': eval_predictions[:, :tlen, num_heldin:],\n",
        "        'eval_rates_heldin_forward': eval_predictions[:, tlen:, :num_heldin],\n",
        "        'eval_rates_heldout_forward': eval_predictions[:, tlen:, num_heldin:]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nlb_tools.evaluation import evaluate\n",
        "from nlb_tools.make_tensors import make_eval_target_tensors\n",
        "\n",
        "target_dict = make_eval_target_tensors(dataset=dataset_large, \n",
        "                                       dataset_name='mc_maze_large',\n",
        "                                       train_trial_split='train',\n",
        "                                       eval_trial_split='val',\n",
        "                                       include_psth=True,\n",
        "                                       save_file=False)\n",
        "\n",
        "evaluate(target_dict, submission)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnoyw22SEgs2"
      },
      "source": [
        "# Part 4: Future Directions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhVxgDDjEk39"
      },
      "source": [
        "## Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy87ZCZSEn-l"
      },
      "source": [
        "## Neural Manifolds"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "CbVaWotNFO8J",
        "vQmhREzM7nWT",
        "nin1SlcK7u3L",
        "XWAIxZyO8H4O",
        "mwngCPOM61Qa",
        "hKqbKEMZ-Is8",
        "Kt0PbGIH-PWc",
        "JaUTfFs7_f9L",
        "N5CuDFgU_jsn",
        "gq-b_TJQ_qnN",
        "RHRyjQAy_3yU",
        "GfSnexQsASHU",
        "urjngpbBBEYn",
        "EIAFz70DBTMj",
        "UQ5bRYBDBWEO",
        "UogRPeL2BaeM",
        "6QVv-lLKCD7n",
        "UE6Wb1AmBnpC",
        "EueGuTLIBsG6",
        "kTOMaJtRCdpI",
        "O3c0Ne0yCwhb",
        "Buayi317DhFr",
        "ckFupmnsDSI5",
        "rTI4WaaVDtCm",
        "cDYLL9S5DyXz",
        "HEcvWBiMDd_1",
        "Tnoyw22SEgs2",
        "GhVxgDDjEk39",
        "Zy87ZCZSEn-l"
      ],
      "name": "CVCalTechWorkshop.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('chenEnv3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "7716fb437acf0fa7345eddc076ed230f692a54d80e26bc61d194e93cc780e808"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
