{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neuroscience-RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing, training, and analyzing recurrent neural networks, Notebook 1\n",
        "\n",
        "### Brandon McMahan & Jonathan Kao\n",
        "\n",
        "### For the CalTech DataSAI Summer School, July 15, 2022.\n",
        "\n",
        "These notebooks will walk you through implementing, training, and analyzing a recurrent neural network for performing the context-dependent integration (CDI) task in _Mante V, Sussillo D, Shenoy KV, Newsome WT. Context-dependent computation by recurrent dynamics in prefrontal cortex. Nature. 2013;503: 78â€“84._\n",
        "\n",
        "This is notebook 1, where you will implement the RNN architecture, initialization, and forward pass."
      ],
      "metadata": {
        "id": "j1WGO9mhDfYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bZFa7OUOzpof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of"
      ],
      "metadata": {
        "id": "A77O07aPzQVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necesary modules\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "aSOnzMk-Eoi3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Brief Introduction To Working in PyTorch\n"
      ],
      "metadata": {
        "id": "XglKmPEozVGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic Differentiation \n",
        "\n",
        "Short lecture on how PyTorch Enables the automatic computation of derivatives followed by an exercise in computing the derivatives for a 'perceptron-like' function.\n"
      ],
      "metadata": {
        "id": "_yIVQ_mjdNpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function and backward propogate it to get the derivatives\n",
        "# we will compute the function f(x) = 3x^2 + 6x - 5\n",
        "# and then evaluate this function at f'(0) and f'(-1)\n",
        "\n",
        "x = torch.tensor([0., -1.], requires_grad=True)\n",
        "f_x = 3*x**2 + 6*x - 5\n",
        "f_x.backward(gradient=torch.tensor([1.,1.]))\n",
        "\n",
        "# now check that the gradients are correct\n",
        "print(\"f'(0) ={0}\\nf'(-1)={1}\".format(x.grad[0], x.grad[1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzhs2NvqdLjK",
        "outputId": "56661dc8-dca1-4600-d4ea-5928011701ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f'(0) =6.0\n",
            "f'(-1)=0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now its your turn\n",
        "Try implementing the function below and using automati differentation to compute the derivaties."
      ],
      "metadata": {
        "id": "m6tjtdvxq7HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## You will implement a function and use the PyTorch autograd library to compute\n",
        "## the derivatives.\n",
        "## \n",
        "## First, define the following function using PyTorch Tensors:\n",
        "##\n",
        "## h(x, y) = g(f(x, y)) where,\n",
        "## g(z) = tanh(z)\n",
        "## f(x,y) = xy \n",
        "## where x, and y are matrices and xy represents the matrix multiplication\n",
        "##\n",
        "## HINT: to multiply two matrices in PyTorch you may use X@Y or toch.matmul(x,y)\n",
        "x = torch.tensor([[.7,-.3,-.4],[-.9,.2,.3]], requires_grad=True)  # x is a 2x3 matrix\n",
        "y = torch.tensor([[1.],[0.],[1.]], requires_grad=True)      # y is a 3x1 matrix\n",
        "\n",
        "## TODO: implement the function to compute h(x,y)\n",
        "\n",
        "## BEGIN SOLUTION\n",
        "f_x_y = torch.matmul(x, y)\n",
        "h_x_y = torch.tanh(f_x_y)\n",
        "\n",
        "print(h_x_y)\n",
        "\n",
        "## TODO: use the autograd library to get the gradients of dh/dx and dh/dy\n",
        "\n",
        "## BEGIN SOLUTION\n",
        "h_x_y.backward(gradient=torch.tensor([[1.],[1.]]))\n",
        "print(x.grad)\n",
        "print(y.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phZxi6qxq5p8",
        "outputId": "c5cb29cd-6ea1-4e9f-fed3-0dd47bdbc457"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2913],\n",
            "        [-0.5370]], grad_fn=<TanhBackward0>)\n",
            "tensor([[0.9151, 0.0000, 0.9151],\n",
            "        [0.7116, 0.0000, 0.7116]])\n",
            "tensor([[ 0.0002],\n",
            "        [-0.1322],\n",
            "        [-0.1526]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use subclassing to Create Neural Network models in PyTorch\n",
        "\n",
        "brief introduction on how to create models with sublcasssing in PyTorch. \n",
        "\n",
        "In short, all we use the following boilerplate code: \n",
        "\n",
        "\n",
        "1.   Our neural network module inherits from the PyTorch nn.Module class\n",
        "2.   We need to initialize our model with all of its weights in __init__\n",
        "3.   we need to define the forward pass\n",
        "\n",
        "After this we have a neural network model that we can use for training and inference\n",
        "\n"
      ],
      "metadata": {
        "id": "6SsNXcSiihGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleNeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    # weight matrix\n",
        "    super(ExampleNeuralNetwork, self).__init__()\n",
        "    self.W = Variable(torch.randn((100, 28)))\n",
        "    # bias vector\n",
        "    self.b = Variable(torch.randn((1,100)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = torch.matmul(x, torch.transpose(self.W, 1, 0))  # batch_size, 100\n",
        "    z = z + self.b\n",
        "    return F.relu(z)\n",
        "\n"
      ],
      "metadata": {
        "id": "89NywVN-isGI"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now its your turn\n",
        "\n",
        "Now try building a simple linear network with a relu activation and 10 output classes.\n",
        "\n",
        "You will use two layers. Each layer will have its own weight and bias. The first layer should map an input from 28 to 100 dimensions. The outputs of this layer should use a ReLU activation.\n",
        "\n",
        "The second layer should map an input from 100 down to 10 dimensions. This layer should use a SoftMax activation."
      ],
      "metadata": {
        "id": "1NvzNdwmjaFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyNeuralNetwork, self).__init__()\n",
        "    ## TODO: define and initialize all the weights and biases you will need\n",
        "    pass\n",
        "  def forward(self, x):\n",
        "    ## TODO: define the forward pass through the network\n",
        "    pass"
      ],
      "metadata": {
        "id": "El2GR_EDjaWT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Inferencing from trained Neural Networks\n",
        "Now we will demonstrate how to write a simple training *loop*"
      ],
      "metadata": {
        "id": "9C-MdOCeku81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance of our neural network\n",
        "my_net = ExampleNeuralNetwork()\n",
        "\n",
        "# forward pass some random data through our network\n",
        "rand_output = my_net(torch.randn((10, 28)))\n",
        "\n",
        "print(rand_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hk9ClKlkyF-",
        "outputId": "f1139c2f-9162-44d5-892c-40e939959455"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Implementation: RNN architecture and forward pass.\n",
        "\n",
        "This part of the notebook will guide you through implementing the architecture and forward pass of the recurrent neural network. As we discussed in the Methods introduction, we do not have to calculate the backwards pass due to PyTorch's autodifferentiation capabilities. (Note that TensorFlow also has this.)\n"
      ],
      "metadata": {
        "id": "MzUPhTIh3EbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we are ready to create an RNN\n",
        "\n",
        "We will implement each of the functions seperately as code blocks and then stitch everything together at the end into a single RNN class\n",
        "\n",
        "### RNN initialization and forward pass\n",
        "\n",
        "While we will later make an RNN class with all these functions, we wanted to separate out the implementation of these functions at first so you can debug each one on its own.\n",
        "\n",
        "Please first complete this notebook, which implements the architecture, initialization, and forward pass of the RNN. After this, we will provide our RNN class with these functions.\n",
        "\n",
        "Also note, that while in the above example we had a single function to forward pass the inputs, here we will define three functions. We will define a ```update_hidden``` function that direclty updates the hidden state. We will write a ```forward``` function whihc passes a single input forward through the RNN and lastly we will implement a ```feed``` function which passes an entire mini-batch of inputs forward through the RNN.\n",
        "\n",
        "#### Network initialization\n",
        "\n",
        "In the following cell, we initialize all variables that will be used to compute the RNN forward pass.\n",
        "\n"
      ],
      "metadata": {
        "id": "CAm-Gih8kcrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Input hyperparameters\n",
        "\n",
        "inputSize = 2       # number of inputs\n",
        "hiddenSize = 5      # number of artificial neurons\n",
        "outputSize = 1      # of outputs\n",
        "\n",
        "## Later on, self.device in the RNN class will be set to either \"cpu\" (to do all computations on the cpu) \n",
        "## or \"cuda:0\" (to do computations on GPU).\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "## Initialization hyperparameter for W_rec, usually g = 1.\n",
        "\n",
        "g = 1\n",
        "\n",
        "## Hyperparameters for the variance of the weight initialization for the input and output weight matrices.\n",
        "\n",
        "inputSigma = 0.5      # input weights standard deviation\n",
        "outputSigma = 0.1     # output weights standard deviation\n",
        "biasScale = 0         # value of the biases\n"
      ],
      "metadata": {
        "id": "2kgBummOkfZz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, you will implement the initialization of all the weights and biases."
      ],
      "metadata": {
        "id": "tNcUHJGanqb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Initialize W[\"in\"], W[\"rec\"], W[\"out\"], and biases. These will be stored in the dictionary self_W.\n",
        "\n",
        "W = []\n",
        "f = torch.tanh\n",
        "\n",
        "## TODO:\n",
        "##\n",
        "##   Initialize all the weights, which are stored in the dictionary self_W.\n",
        "##\n",
        "##   The RNN equation is:\n",
        "## \n",
        "##     x_{t+1} = (1-alpha) * x_t + (1-alpha) * (W_{rec} * f(x_t) + W_in * u_t + bias)\n",
        "##\n",
        "##   Here, the matrices are:\n",
        "##     W_{in} is W[\"in\"]\n",
        "##     W_{rec} is W[\"rec\"]\n",
        "##     W_{out} is W[\"out\"]\n",
        "##     bias is self_W[\"bias\"]\n",
        "##     The activation function is f\n",
        "##\n",
        "##   The initializations should be:\n",
        "##     W_{in} ~ N(0, (self.inputSigma)^2)\n",
        "##     W_{rec} ~ N(0, (self.g**2 / self.hiddenSize)^2)\n",
        "##     W_{out} ~ N(0, (self.outputSigma)^2)\n",
        "##     bias ~ N(0, self.biasScale) \n",
        "##\n",
        "##   Note 1: these should all be Torch tensors (not numpy arrays!)\n",
        "##   Note 2: for this implementation, bias should be (self_hiddenSize,).\n",
        "##\n",
        "##   To make all of these CUDA compatible (i.e., able to run on GPU), append \".to(self_device)\" after.\n",
        "##   While these will run on the CPU, later on, this will enable us to run on the GPU if self.device in the RNN class is set to the GPU.\n",
        "##    \n",
        "##   EXAMPLE:\n",
        "##\n",
        "##     W['in'] = 0.5 * torch.randn(self_hiddenSize, self.inputSize)\n",
        "##       becomes\n",
        "##     W['in'] = (0.5 * torch.randn(self_hiddenSize, self.inputSize)).to(self_device)\n",
        "##\n",
        "##   Lastly, as we will do a check to make sure you initialized correctly, you should only make \n",
        "##    three calls to torch.randn; one for W_{in}, W_{rec}, and W_{out}\n",
        "\n",
        "# Set the random seed so our results are comparable.\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "## BEGIN SOLUTION\n",
        "W = {\n",
        "    'in' : torch.randn(self_hiddenSize, self_inputSize).to(self_device)*self_inputSigma,\n",
        "    'rec' : ((self_g**2)/self_hiddenSize)*torch.randn(self_hiddenSize, self_hiddenSize).to(self_device),\n",
        "    'out' : (self_outputSigma*torch.randn(self_outputSize, self_hiddenSize).to(self_device)),\n",
        "    'bias' : torch.zeros(self_hiddenSize,).to(self_device)*self_biasScale,\n",
        "    }\n",
        "\n",
        "## END SOLUTION"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "rc4x1cGAnwKe",
        "outputId": "cb1b5e4c-a659-4095-a326-541989905afd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-dfaff16b8a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m## BEGIN SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m W = {\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;34m'in'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_hiddenSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_inputSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself_inputSigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;34m'rec'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_g\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself_hiddenSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_hiddenSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_hiddenSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m'out'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself_outputSigma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_hiddenSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self_hiddenSize' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialization implementation check\n",
        "\n",
        "Run the following code to check your initialization dimensions and values. Because we set the random seed, you should get the same results. \n",
        "\n",
        "All the assertions should pass if your initializations are correct."
      ],
      "metadata": {
        "id": "zUDE72F0rfxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check on dimensions and types\n",
        "\n",
        "assert W[\"in\"].numpy().shape == (self_hiddenSize, self_inputSize), \"Dimensions of W_in are incorrect.\"\n",
        "assert W[\"rec\"].numpy().shape == (self_hiddenSize, self_hiddenSize), \"Dimensions of W_rec are incorrect.\"\n",
        "assert W[\"out\"].numpy().shape == (self_outputSize, self_hiddenSize), \"Dimensions of W_out are incorrect.\"\n",
        "assert W[\"bias\"].numpy().shape == (self_hiddenSize,), \"Dimensions of bias are incorrect.\"\n",
        "assert torch.is_tensor(W[\"in\"]), \"W_in is not a torch.FloatTensor\"\n",
        "assert torch.is_tensor(W[\"rec\"]), \"W_rec is not a torch.FloatTensor\"\n",
        "assert torch.is_tensor(W[\"out\"]), \"W_out is not a torch.FloatTensor\"\n",
        "assert torch.is_tensor(W[\"bias\"]), \"bias is not a torch.FloatTensor\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "smWmTAQRnwOu",
        "outputId": "a92e8e7a-082c-4466-894b-942e9a8295f1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-131301cf9d50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check on dimensions and types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"in\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself_hiddenSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_inputSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dimensions of W_in are incorrect.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself_hiddenSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_hiddenSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dimensions of W_rec are incorrect.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself_outputSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_hiddenSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dimensions of W_out are incorrect.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check on values\n",
        "\n",
        "assert torch.sum(torch.abs(self_W['in'] - torch.tensor((( 0.7705, -0.1467), (-1.0894,  0.2842), (-0.5423, -0.6993), ( 0.2017,  0.4190), (-0.3596, -0.2017))))) <= 1e-2, \"W_in initialization is not correct\"\n",
        "assert torch.sum(torch.abs(self_W['rec'] - torch.tensor((( 0.1198, -0.3110, -0.0683,  0.3706,  0.0936), (-0.0315,  0.2887,  0.0532,  0.2779, -0.1357), ( 0.1877,  0.0978, -0.1346,  0.1746,  0.2111), ( 0.0356, -0.0461, -0.0613, -0.3162,  0.3413), (-0.0892,  0.1488,  0.3042,  0.6821, -0.3062))))) <= 1e-2, 'W_rec initialization is not correct'\n",
        "assert torch.sum(torch.abs(self_W['out'] - torch.tensor(((-0.0531, -0.0431, -0.2286,  0.0070,  0.0667))))) < 1e-2, 'W_out initialization is not correct'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "fWC21F9lnwQk",
        "outputId": "2faad05a-5e83-4074-cdb4-9defe5c799e9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-8171de1ebc35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check on values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_W\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m0.7705\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.1467\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0894\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.2842\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5423\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.6993\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m0.2017\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.4190\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.3596\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.2017\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"W_in initialization is not correct\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_W\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m0.1198\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.3110\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.0683\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.3706\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.0936\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.0315\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.2887\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.0532\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.2779\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.1357\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m0.1877\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.0978\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.1346\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.1746\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.2111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m0.0356\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.0461\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.0613\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.3162\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.3413\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.0892\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.1488\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.3042\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.6821\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.3062\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'W_rec initialization is not correct'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_W\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.0531\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.0431\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.2286\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.0070\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.0667\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'W_out initialization is not correct'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self_W' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "53v-iP7ToAF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement hidden state update for one time step\n",
        "\n",
        "In this section, you will now write a function, \"out = updateHidden(inpt)\" that takes in one set of RNN inputs and computes the next hidden state. When we say hidden_state here, we are referring to the pre-activation hidden state, x, and not f(x) (where f is the nonlinearity). To calculate the next hidden_state requires the previous hidden_state, which we will assume is stored as \"self.hidden\". This update is just for ONE time step and one input. We will later use these functions to calculate all the hidden states and outputs across all time."
      ],
      "metadata": {
        "id": "lwgBSfv5oAal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## You will implement the updateHidden function.\n",
        "##\n",
        "##     x_{t+1} = (1-alpha) * x_t + (1-alpha) * (W_{rec} * f(x_t) + W_in * u_t + bias)\n",
        "##\n",
        "## Assume that alpha = 1/self.dt\n",
        "##\n",
        "## \n",
        "\n",
        "def updateHidden(hidden_current, inpt):\n",
        "    '''Updates the hidden state of the RNN for one time step.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        hidden_curent: PyTorch Tensor\n",
        "            current hidden state\n",
        "        inpt: PyTorch Tensor\n",
        "            inputs to the network at current time step. Has shape (inputSize, batchSize)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        hidden_next: PyTorch cuda Tensor\n",
        "            Tensor of the updated neuron activations. Has shape (hiddenSize, batchSize)\n",
        "\n",
        "    '''\n",
        "    \n",
        "    self_dt = 10\n",
        "    alpha = 1/self_dt\n",
        "    \n",
        "    ## TODO: Implement one time step to update the hidden activation.\n",
        "    \n",
        "    ## BEGIN SOLUTION\n",
        "\n",
        "    # forward pass through the network\n",
        "    hidden_next = alpha*torch.matmul(W[\"in\"], inpt) + \\\n",
        "        alpha*torch.matmul(W['rec'], self_f(hidden_current)) + \\\n",
        "        (1-alpha)*hidden_current + alpha*W['bias']\n",
        "    \n",
        "    ## END SOLUTION\n",
        "    \n",
        "    return hidden_next\n",
        "    "
      ],
      "metadata": {
        "id": "kZ3FPwC9nwUG"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### updateHidden implementation check\n",
        "\n",
        "The following checks your implementation of updateHidden.\n",
        "\n",
        "Be sure that self_W is one that passed all the prior implementation checks."
      ],
      "metadata": {
        "id": "_lhBRbweoJ95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## code to check updateHidden\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "hidden_current = torch.randn((hiddenSize,))\n",
        "inpt = torch.randn((inputSize,))\n",
        "hidden_next = updateHidden(hidden_current, inpt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "8h5BW8ZhoPLJ",
        "outputId": "1437fcc3-8ba4-4267-80db-f622f0e0bfc7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-286b1f53742c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhidden_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiddenSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhidden_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdateHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-335aa521984d>\u001b[0m in \u001b[0;36mupdateHidden\u001b[0;34m(hidden_current, inpt)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# forward pass through the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mhidden_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"in\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m         \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhidden_current\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m## END SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute output for one time step\n",
        "\n",
        "Next, we will compute the output of the RNN for an input. You should use the updateHidden() function here. Be sure your updateHidden() passed the implementation check.\n",
        "\n",
        "Computing the output given the inputs is typically called the forward pass, and so this function is called \"forward\".\n"
      ],
      "metadata": {
        "id": "hOh5OgCkoKCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(hidden_current, inpt):\n",
        "    '''\n",
        "    Computes the RNNs forward pass output for a single timestep\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    hidden_curent: PyTorch Tensor\n",
        "        current hidden state\n",
        "    inpt: PyTorch Tensor \n",
        "        inputs to the network for the current timestep. Shape (inputSize, batchSize)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    output: PyTorch Tensor\n",
        "        output of the network after this timestep. Has shape (outputSize, batchSize)\n",
        "    hidden_next: PyTorch Tensor\n",
        "        copy of the hidden state activations after the forward pass. Has shape\n",
        "        (hiddenSize, batchSize)\n",
        "\n",
        "    '''\n",
        "    \n",
        "    # assert that inputs are torch tensors \n",
        "    assert torch.is_tensor(hidden_current), \"Current hidden state is not a torch tensor.\"\n",
        "    assert torch.is_tensor(inpt), \"Input is not a torch tensor.\"\n",
        "\n",
        "\n",
        "    ## BEGIN SOLUTION\n",
        "    hidden_next = UpdateHidden(inpt)\n",
        "    output = torch.matmul(self_W['out'], hidden_next)\n",
        "\n",
        "    ## END SOLUTION\n",
        "\n",
        "    return output, hidden_next.clone()\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "DKnI-YtxoVQs"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now compute all hidden states and outputs for all time steps\n",
        "\n",
        "We will now use the forward() function you implemented to compute the forward pass for all time steps. We will call this function \"feed()\"."
      ],
      "metadata": {
        "id": "uAdfCcSLoKEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T = 10\n",
        "\n",
        "torch.manual_seed(0)\n",
        "inpt_data = torch.randn((inputSize, T)) # of dimensions (inputSize, Time)\n",
        "\n",
        "## Note that in the class, our feed function will also be able to take batches of data\n",
        "## but in this case, we'll just do it for one batch.\n",
        "\n",
        "def feed(self, inpt_data):\n",
        "    '''\n",
        "    Feeds an input data sequence into an RNN\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    inpt_data : PyTorch Tensor\n",
        "        Inputs sequence to be fed into RNN. Has shape (inputSize, Time)\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    output_trace : PyTorch Tensor\n",
        "        output_trace: output of the network over all timesteps. Will have shape \n",
        "        (T,) i.e. 40x1 for single sample inputs\n",
        "    hidden_states : PyTorch Tensor\n",
        "        hidden_states: pre-activation hidden states of the network through a trial, has shape\n",
        "        (hidden_size, T)\n",
        "\n",
        "    '''\n",
        "\n",
        "    #num_inputs = len(inpt_data[0])\n",
        "    batchSize = inpt_data.shape[0]\n",
        "    T = inpt_data.shape[1]\n",
        "    assert inpt_data.shape[0] == inputSize, \"Size of inputs:{} does not match network's input size:{}\".format(inpt_data.shape[1], self_inputSize)\n",
        "\n",
        "    # Normally the hidden size and output size are stored as class variables. For this function, we will \n",
        "    # simply define output_trace for a 1D output, and assume the hiddenSize is 5, continuing our example above.\n",
        "    # These are hard-coded in, but in the class, they will be stored as e.g. self.hiddenSize.\n",
        "    \n",
        "    output_trace = torch.zeros(num_t_steps)\n",
        "    hidden_states = torch.zeros((5,T), requires_grad=True)\n",
        "    hidden_current = torch.zeros((5,))\n",
        "    \n",
        "    ## BEGIN SOLUTION # still in progress\n",
        "    inpt_data = inpt_data.permute(1,0)     # now has shape TxMxB\n",
        "    for t_step in range(len(inpt_data)):\n",
        "        output, hidden = self._forward(inpt_data[t_step])\n",
        "        output_trace[t_step,:] = output\n",
        "\n",
        "    ## END SOLUTION\n",
        "    \n",
        "    return output_trace, hidden_states"
      ],
      "metadata": {
        "id": "EjfDBURUobhw"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the RNN class\n",
        "\n",
        "Congratulations on implementing the functions needed to build an RNN! We will now import the RNN class which just contains all the functions you have implemented. You can check out the RNN class in rnn.py if you want to see more details. For now, just understand that we have just copied the functions implemented above into the RNN class."
      ],
      "metadata": {
        "id": "VZ6CqCXVuVeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rnn import RNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "Xx6w6VF6urpB",
        "outputId": "b5532d4c-a1fa-4a9d-ac78-2ce14bd4dc9c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-6d4f69007f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rnn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Building the Training Data Pipeline\n",
        "\n",
        "Now that the RNN weights and forward pass have been implemented, next we are going to create our training data. We will be training these RNNs to perform the Context Dependent Integration (CDI) task as desribed in Mante and Susillo 2013. "
      ],
      "metadata": {
        "id": "s3i426WYoKIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First model the task"
      ],
      "metadata": {
        "id": "YaJs9510oKRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _random_generate_input(self, mean, trial_prob=0.5):\n",
        "        '''\n",
        "        Generates a 1D noisy signal for a context with the provided mean. \n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        mean : float\n",
        "          the mean value of the noisy context signal\n",
        "        trial_prob : float\n",
        "          the probability that this trial shoudl be positive\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        context_input : torch tensor\n",
        "          Noisy context signal with dimensions (750,)\n",
        "        \n",
        "        The \n",
        "        chance of a positive trial is given by trial_prob.\n",
        "        '''\n",
        "        ## TODO: implement this\n",
        "        context_input = None\n",
        "\n",
        "        ## BEGIN \n",
        "        \n",
        "        # with probability trial_prob generate a positive trial\n",
        "        if torch.rand(1).item() < trial_prob:\n",
        "          context_input = mean*torch.ones(self.N)\n",
        "        else:\n",
        "          context_input = -mean*torch.ones(self.N)  \n",
        "           \n",
        "        # add some noise to the signal\n",
        "        context_input += torch.randn(self.N)  \n",
        "        ## END SOLUTION\n",
        "\n",
        "        return context_input"
      ],
      "metadata": {
        "id": "XKQMRjWUu5Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GetInput(self, mean_overide=None, var_overide=None):\n",
        "        '''\n",
        "        Generates a single trial of data for the CDI-task. Returns the\n",
        "        perceptual data (inpts) and the labels (target)\n",
        "\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mean_overide : TYPE, optional\n",
        "            DESCRIPTION. The default is 1.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        inpts : PyTorch CUDA Tensor\n",
        "            DESCRIPTION.\n",
        "        target : TYPE\n",
        "            DESCRIPTION.\n",
        "        '''\n",
        "        inpts = torch.zeros((self.N, 2*self.N_INPUT_CHANNELS)).to(self._device)\n",
        "        \n",
        "        # sample trial mean from ~U[-max_mean, max_mean]\n",
        "        mean = torch.rand(1).item() * self._max_mean\n",
        "\n",
        "        # allows caller to use a deterministic mean for this trial\n",
        "        if mean_overide is not None:\n",
        "            mean = mean_overide\n",
        "\n",
        "        # allows caller to override the default noise\n",
        "        if var_overide is not None:\n",
        "            var = var_overide\n",
        "        else:\n",
        "            var = self._var  \n",
        "\n",
        "        # randomly sets one of the channels to be on\n",
        "        go_channel = randrange(self.N_INPUT_CHANNELS)\n",
        "        for channel_num in range(self.N_INPUT_CHANNELS):\n",
        "            inpts[:,channel_num] = self._random_generate_input(mean)\n",
        "            # generate the GO signals\n",
        "            if go_channel == channel_num:\n",
        "                inpts[:, self.N_INPUT_CHANNELS + channel_num] = 1\n",
        "                target = torch.sign(torch.mean(inpts[:, channel_num]))\n",
        "            else:\n",
        "                inpts[:, self.N_INPUT_CHANNELS + channel_num] = 0\n",
        "\n",
        "        \n",
        "        # adds noise to inputs\n",
        "        inpts[:,:self.N_INPUT_CHANNELS] += var*torch.randn(self.N, \n",
        "            self.N_INPUT_CHANNELS).to(self._device)\n",
        "        return inpts, target\n",
        "      "
      ],
      "metadata": {
        "id": "d46r13dGvEHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import the task class \n",
        "Now that you have implemented the code to model the trainin task, we can import the ContextDpendentIntegration task which uses this code to generate training data for the RNN class.\n",
        "\n"
      ],
      "metadata": {
        "id": "7q9WIpx4zB6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Writing a training loop\n",
        "Now we can use the RNN class and the torch class to write a training loop to train our RNN. We will implement the following functions:\n",
        "\n",
        "## get_loss\n",
        "This function will compute the loss between the RNN outputs and the target outputs for the trial\n",
        "\n",
        "## train one trial\n",
        "This function will train the RNN on a single (mini-batch) of trials. \n",
        "\n",
        "## train\n",
        "This function will pull everything together and train the RNN by looping over (mini-batches) of trials to train the RNN until we attain a validation accuracy of some target threshold (95% accuracy by default)"
      ],
      "metadata": {
        "id": "gbQuq4TJzB8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement the loss fucntion\n",
        "def loss_fn(target, output):\n",
        "\n",
        "        # extract start and end of output\n",
        "        y_end = output[-1]\n",
        "        y_strt = output[0]\n",
        "\n",
        "        # use loss from Mante 2013\n",
        "        squareLoss = (y_end-torch.sign(target.T))**2 + (y_strt - 0)**2\n",
        "        SquareLoss = torch.sum( squareLoss, axis=0 )\n",
        "        return SquareLoss  "
      ],
      "metadata": {
        "id": "gbb25Em_z8iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement the train one epoch function\n",
        "\n",
        "def train_one_batch(rnn, input, trial, condition):\n",
        "    '''\n",
        "    trains a model on a single batch of trials\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input : PyTorch A Tensor\n",
        "        Inputs sequence to be fed into RNN. Has shape (batchSize, sequence_len, inputSize)\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    output : PyTorch CUDA Tensor\n",
        "    '''\n",
        "\n",
        "    batch_size, inpt_seq_len, input_size = input.shape      # input dimensions\n",
        "\n",
        "    #create an activities tensor for the rnn_model\n",
        "    \n",
        "    #self.StoreRecMag()\n",
        "\n",
        "    output = torch.zeros((self._task.N, batch_size*self._outputSize)) \n",
        "    output_temp = torch.Tensor([0])\n",
        "\n",
        "    trial_length = self._task.N\n",
        "    #hidden_states = torch.zeros((batch_size, inpt_seq_len, self._hiddenSize), requires_grad=True)\n",
        "    for i in range(trial_length): \n",
        "        inputNow = input[:,i,:].t()\n",
        "        output_temp, hidden = self._forward(inputNow)           #I need to generalize this line to work for context task\n",
        "        #hidden_states[:,i,:] = hidden.T                         # (batch_size, hidden_size)\n",
        "        #output_temp, hidden = self.rnn_model.forward(input[:,i], hidden, dt)             #this incridebly hacky must improve data formatting accross all modules to correctly implement a context task that doesn't clash with DM task\n",
        "        output[i] = np.squeeze(output_temp)\n",
        "        if (i %10 == 0):\n",
        "            activityIX = int(i/10)\n",
        "            self._activityTensor[self.trial_count, activityIX, :] = np.squeeze(torch.tanh(self._hidden).cpu().detach().numpy())[:,0]\n",
        "    self.trial_count += 1\n",
        "    # self.activity_tensor[trial, i, :] = hidden.detach().numpy()  # make sure calling detach does not mess with the backprop gradients (I think .data does)\n",
        "    # https://pytorch.org/docs/stable/autograd.html\n",
        "    #pdb.set_trace()\n",
        "    loss = self.loss_fn(condition, output)\n",
        "    loss.backward()\n",
        "    self._optimizer.step()\n",
        "    \n",
        "    return output, loss.item()"
      ],
      "metadata": {
        "id": "rrEwQFsfz8ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement the train function\n",
        "def train(rnn, termination_accuracy=0.9):\n",
        "    '''\n",
        "    Trains RNN to termination accuracy\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    '''\n",
        "\n",
        "    optimizer = torch.optim.Adam(rnn._params, lr=5e-4)\n",
        "    # pre-generate a set of validation trials that will be constant throughout training\n",
        "    rnn.createValidationSet()\n",
        "    # create activity tensor\n",
        "    #self._activityTensor = np.zeros((self._num_epochs, int(self._task.N/10), self._hiddenSize))\n",
        "\n",
        "    \n",
        "    # inps_save = np.zeros((num_epochs, trial_length))\n",
        "    trial_count=0\n",
        "    targets = []   #will hold target output for each trial\n",
        "    \n",
        "    validation_accuracy = 0.0\n",
        "    validation_acc_hist = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    meanLossHist = 100*np.ones(20)\n",
        "    # empty list that will hold history of validation accuracy\n",
        "    loss_hist = []\n",
        "    \n",
        "    # for CUDA implementation\n",
        "    inpt = Variable(torch.zeros(int(self._batchSize), self._task.N, self._inputSize).to(self._device))\n",
        "    \n",
        "    #trial = 0\n",
        "    loss = np.inf\n",
        "    \n",
        "    # start main training loop\n",
        "    while(validation_accuracy < termination_accuracy):\n",
        "        # terminate training after maximum allowed epochs\n",
        "        if self.trial_count >= self._num_epochs:\n",
        "            break\n",
        "        \n",
        "        # periodically prints training status\n",
        "        if self.trial_count %PRINT_EVERY == 0:\n",
        "            print('trial #:', self.trial_count)\n",
        "            print('validation accuracy', validation_accuracy)\n",
        "            print(\"validation history\", validation_acc_hist)\n",
        "        #print('loss', loss)\\\n",
        "        \n",
        "        \n",
        "        # generate a batch of training trials\n",
        "        # I should move the getBatch method to the data class\n",
        "        inpt[:], condition = self.getBatch()    # inpt has shape 750x1\n",
        "        self.targets.append(condition[-1].item())\n",
        "        condition = Variable(condition)\n",
        "        \n",
        "        # train model on this data    \n",
        "        rnn._init_hidden()   # resets the hidden state for new trials\n",
        "        # train the network on this batch of trials\n",
        "        optimizer.zero_grad()\n",
        "        output, loss = train_one_batch(inpt, self.trial_count, condition)\n",
        "        \n",
        "        # append current loss to history\n",
        "        self.all_losses.append(loss)\n",
        "\n",
        "        validation_accuracy_curr = self.GetValidationAccuracy()\n",
        "        loss_hist.append(1-validation_accuracy_curr)\n",
        "        #print('loss hist', np.mean(np.diff(meanLossHist)))\n",
        "        validation_acc_hist[:9] = validation_acc_hist[1:]\n",
        "        validation_acc_hist[-1] = validation_accuracy_curr\n",
        "        meanLossHist[:19] = meanLossHist[1:]\n",
        "        meanLossHist[-1] = np.mean(self.all_losses[-20:])\n",
        "        validation_accuracy = np.min(validation_acc_hist)\n",
        "              \n",
        "        \n",
        "        # save the model every 100 trials\n",
        "        # why am I saving the model twice?\n",
        "        if self.trial_count %100 == 0:\n",
        "            self.saveProgress()\n",
        "        \n",
        "    self._targets = np.array(self.targets)        #hacky\n",
        "    self._losses = np.array(self.all_losses)#self.all_losses      #also hacky\n",
        "    self._activityTensor = self._activityTensor[:self.trial_count,:,:]\n",
        "    print('shape of activity tensor', self._activityTensor.shape)  \n",
        "    print('trial count', self.trial_count)\n",
        "    self._endTimer()\n"
      ],
      "metadata": {
        "id": "s1r1DSCvz8m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Visualizing RNN Behavior\n",
        "\n",
        "## Psychometric Curves\n",
        "write a function to generate psychometric *curves*"
      ],
      "metadata": {
        "id": "VPTIz_p4zB-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize attractor States\n",
        "Write a function to find the attractor states in the RNN"
      ],
      "metadata": {
        "id": "KhfLIOa2zCAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4q-e6I3UzCCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_JyWkfPbzCEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NMcxThJAzCG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rCbLadU5zCJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7T-fRC4szCMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gq1Cpt_IzCOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6juedLuozCP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZQW9lJRSzCRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "azXTMmFrzCTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fJnZ5XHrzCU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bt0jJrnkzCWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class for generating data \n",
        "class ContextDependentIntegration():\n",
        "    '''\n",
        "    This class simulates the Mante and Sussillo 2013 context-dependent \n",
        "    integration task described here:\n",
        "\n",
        "    https://www.nature.com/articles/nature12742\n",
        "    '''\n",
        "\n",
        "    N_INPUT_CHANNELS = 2\n",
        "\n",
        "    def __init__(self, N=750, mean=0.1857, var=1, device=\"cuda:0\"):\n",
        "        # determines if code should run on CPU or GPU\n",
        "        if torch.cuda.is_available() and device==\"cuda:0\":\n",
        "            self._device = torch.device(device)\n",
        "        else:\n",
        "            self._device = torch.device(\"cpu\")\n",
        "\n",
        "        self.N = N                 # number of time steps in a trial\n",
        "        self._max_mean = mean      # maximum mean value of signal\n",
        "        self._var = var            # variance of signal\n",
        "        #self._version = \"\"        # is this deprecated ??\n",
        "        #self._name = \"Ncontext\"   # is this deprecated ??\n",
        "\n",
        "    def _random_generate_input(self, mean, trial_prob=0.5):\n",
        "        '''\n",
        "        Generates a 1D noisy signal for a context with the provided mean. The \n",
        "        chance of a positive trial is given by trial_prob.\n",
        "        '''\n",
        "        if torch.rand(1).item() < trial_prob:\n",
        "            return mean*torch.ones(self.N)\n",
        "        return -mean*torch.ones(self.N)\n",
        "        \n",
        "    def GetInput(self, mean_overide=None, var_overide=None):\n",
        "        '''\n",
        "        Generates a single trial of data for the CDI-task. Returns the\n",
        "        perceptual data (inpts) and the labels (target)\n",
        "\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mean_overide : TYPE, optional\n",
        "            DESCRIPTION. The default is 1.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        inpts : PyTorch CUDA Tensor\n",
        "            DESCRIPTION.\n",
        "        target : TYPE\n",
        "            DESCRIPTION.\n",
        "        '''\n",
        "        inpts = torch.zeros((self.N, 2*self.N_INPUT_CHANNELS)).to(self._device)\n",
        "        \n",
        "        # sample trial mean from ~U[-max_mean, max_mean]\n",
        "        mean = torch.rand(1).item() * self._max_mean\n",
        "\n",
        "        # allows caller to use a deterministic mean for this trial\n",
        "        if mean_overide is not None:\n",
        "            mean = mean_overide\n",
        "\n",
        "        # allows caller to override the default noise\n",
        "        if var_overide is not None:\n",
        "            var = var_overide\n",
        "        else:\n",
        "            var = self._var  \n",
        "\n",
        "        # randomly sets one of the channels to be on\n",
        "        go_channel = randrange(self.N_INPUT_CHANNELS)\n",
        "        for channel_num in range(self.N_INPUT_CHANNELS):\n",
        "            inpts[:,channel_num] = self._random_generate_input(mean)\n",
        "            # generate the GO signals\n",
        "            if go_channel == channel_num:\n",
        "                inpts[:, self.N_INPUT_CHANNELS + channel_num] = 1\n",
        "                target = torch.sign(torch.mean(inpts[:, channel_num]))\n",
        "            else:\n",
        "                inpts[:, self.N_INPUT_CHANNELS + channel_num] = 0\n",
        "\n",
        "        \n",
        "        # adds noise to inputs\n",
        "        inpts[:,:self.N_INPUT_CHANNELS] += var*torch.randn(self.N, \n",
        "            self.N_INPUT_CHANNELS).to(self._device)\n",
        "        return inpts, target\n",
        "      "
      ],
      "metadata": {
        "id": "fWexBHNpsIxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y2UWVJLFoKTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J_C7SkWAoKV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XBakht_qoKX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1IvHdTeCoKbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Add a section on how to build different RNN architectures in python\n",
        "\n",
        "Add some intuition of BPTT\n",
        "\n",
        "Add some inutition on the pros/cons of these methods for neuroscience\n"
      ],
      "metadata": {
        "id": "prpXi2MX2xrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build an RNN"
      ],
      "metadata": {
        "id": "RIMkRO4PDmnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bH2wpE77DhoV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Data Loader"
      ],
      "metadata": {
        "id": "0MRcJrjfDqNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eggNkeS8Dpka"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize a few trials\n",
        "training_task = ContextDependentIntegration()\n",
        "\n",
        "'''for sample_ix in range(10):\n",
        "    sample_trial, sample_target = training_task.GetInput(mean_overide=1, \n",
        "                                                         var_overide=0.25)\n",
        "\n",
        "\n",
        "    plt.figure(sample_ix)\n",
        "    plt.plot(sample_trial.cpu()[:,0])\n",
        "    plt.plot(sample_trial.cpu()[:,1])\n",
        "    plt.plot(sample_trial.cpu()[:,2])\n",
        "    plt.plot(sample_trial.cpu()[:,3])\n",
        "    plt.legend([\"context 1\", \"context 2\", \"GO 1\", \"GO 2\"])\n",
        "    plt.title(\"Goal: \" + str(sample_target.item()))'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "P15t4nB5ETln",
        "outputId": "4b63ec55-c7ea-44bf-8914-9b8c3ff4dfb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for sample_ix in range(10):\\n    sample_trial, sample_target = training_task.GetInput(mean_overide=1, \\n                                                         var_overide=0.25)\\n\\n\\n    plt.figure(sample_ix)\\n    plt.plot(sample_trial.cpu()[:,0])\\n    plt.plot(sample_trial.cpu()[:,1])\\n    plt.plot(sample_trial.cpu()[:,2])\\n    plt.plot(sample_trial.cpu()[:,3])\\n    plt.legend([\"context 1\", \"context 2\", \"GO 1\", \"GO 2\"])\\n    plt.title(\"Goal: \" + str(sample_target.item()))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nOthPz7rETn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M0s7bf9LETqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OSvi_EYzETx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lm79WSiMET0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write a training loop"
      ],
      "metadata": {
        "id": "DMrAJ83CDsjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1ZMfScbKDt9f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyper_params = {                  # dictionary of all RNN hyper-parameters\n",
        "   \"inputSize\" : 4,\n",
        "   \"hiddenSize\" : 50,\n",
        "   \"outputSize\" : 1,\n",
        "   \"g\" : 1 ,\n",
        "   \"inputVariance\" : 0.5,\n",
        "   \"outputVariance\" : 0.5,\n",
        "   \"biasScale\" : 0,\n",
        "   \"initScale\" : 0.3,\n",
        "   \"dt\" : 0.1,\n",
        "   \"batchSize\" : 500,\n",
        "   \"taskMean\" : 0.1857,\n",
        "   \"taskVar\" : 1,\n",
        "   \"ReLU\" : 0\n",
        "   }\n",
        "\n",
        "my_rnn = BPTT(hyper_params, training_task)"
      ],
      "metadata": {
        "id": "UJVgnxoVTd8W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_rnn.setName(\"tmp\")\n",
        "import time"
      ],
      "metadata": {
        "id": "dHMGE6Z0VSaS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_rnn.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j786aFh7Vcun",
        "outputId": "b354d3e1-cc5c-4bbb-9a5b-e060bb646ce9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.7/bdb.py\", line 332, in set_trace\n",
            "    sys.settrace(self.trace_dispatch)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> <ipython-input-3-1925a9166785>(120)createValidationSet()\n",
            "-> self.validationData = torch.zeros(test_iters, self._inputSize,  self._task.N).to(self._device)\n",
            "(Pdb) c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.7/bdb.py\", line 343, in set_continue\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation dataset created!\n",
            "\n",
            "trial #: 0\n",
            "validation accuracy 0.0\n",
            "validation history [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trial #: 10\n",
            "validation accuracy 0.4695\n",
            "validation history [0.54, 0.5465, 0.5385, 0.5245, 0.504, 0.491, 0.484, 0.4765, 0.4695, 0.47]\n",
            "trial #: 20\n",
            "validation accuracy 0.4755\n",
            "validation history [0.4755, 0.4795, 0.486, 0.489, 0.5, 0.5065, 0.5085, 0.507, 0.509, 0.5085]\n",
            "trial #: 30\n",
            "validation accuracy 0.4775\n",
            "validation history [0.5085, 0.5085, 0.501, 0.4985, 0.49, 0.4895, 0.486, 0.4785, 0.4775, 0.479]\n",
            "trial #: 40\n",
            "validation accuracy 0.4785\n",
            "validation history [0.4785, 0.482, 0.488, 0.4865, 0.484, 0.489, 0.4945, 0.497, 0.5055, 0.507]\n",
            "trial #: 50\n",
            "validation accuracy 0.5055\n",
            "validation history [0.5095, 0.507, 0.5055, 0.5095, 0.5135, 0.5145, 0.517, 0.519, 0.523, 0.529]\n",
            "trial #: 60\n",
            "validation accuracy 0.53\n",
            "validation history [0.5305, 0.53, 0.536, 0.5375, 0.5405, 0.546, 0.552, 0.554, 0.5555, 0.56]\n",
            "trial #: 70\n",
            "validation accuracy 0.5605\n",
            "validation history [0.561, 0.562, 0.5625, 0.563, 0.5605, 0.5615, 0.5685, 0.569, 0.5675, 0.572]\n",
            "trial #: 80\n",
            "validation accuracy 0.5745\n",
            "validation history [0.5745, 0.5835, 0.585, 0.5895, 0.584, 0.582, 0.5805, 0.583, 0.5935, 0.599]\n",
            "trial #: 90\n",
            "validation accuracy 0.602\n",
            "validation history [0.602, 0.6045, 0.609, 0.6085, 0.609, 0.613, 0.619, 0.6175, 0.619, 0.621]\n",
            "valdiation history [0.54, 0.5465, 0.5385, 0.5245, 0.504, 0.491, 0.484, 0.4765, 0.4695, 0.47, 0.4755, 0.4795, 0.486, 0.489, 0.5, 0.5065, 0.5085, 0.507, 0.509, 0.5085, 0.5085, 0.5085, 0.501, 0.4985, 0.49, 0.4895, 0.486, 0.4785, 0.4775, 0.479, 0.4785, 0.482, 0.488, 0.4865, 0.484, 0.489, 0.4945, 0.497, 0.5055, 0.507, 0.5095, 0.507, 0.5055, 0.5095, 0.5135, 0.5145, 0.517, 0.519, 0.523, 0.529, 0.5305, 0.53, 0.536, 0.5375, 0.5405, 0.546, 0.552, 0.554, 0.5555, 0.56, 0.561, 0.562, 0.5625, 0.563, 0.5605, 0.5615, 0.5685, 0.569, 0.5675, 0.572, 0.5745, 0.5835, 0.585, 0.5895, 0.584, 0.582, 0.5805, 0.583, 0.5935, 0.599, 0.602, 0.6045, 0.609, 0.6085, 0.609, 0.613, 0.619, 0.6175, 0.619, 0.621, 0.621, 0.6225, 0.6235, 0.6245, 0.627, 0.627, 0.6305, 0.6375, 0.643, 0.639]\n",
            "model name:  models/tmp.pt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3420098c7de4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-35b94736a3c4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, termination_accuracy)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# why am I saving the model twice?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_count\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveProgress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m#hacky\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-35b94736a3c4>\u001b[0m in \u001b[0;36msaveProgress\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#self.all_losses      #also hacky\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m#self.rnn_model.activity_tensor = self.rnn_model.activity_tensor[:self.trial_count,:,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model back-ed up'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-1925a9166785>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, N, tElapsed, *kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtElapsed\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             torch.save({'weights': self._J,                         'weight_hist':self._w_hist,                         'activities': self._activityTensor,                         'targets': self._targets,                         'pca': self._pca,                         'losses': self._losses,                         'rec_magnitude' : self._recMagnitude,                         'neuron_idx': self._neuronIX,                        'validation_history' : self._valHist,\n\u001b[0;32m--> 305\u001b[0;31m                         'fixed_points': self._fixedPoints}, model_name)\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;31m# save model hyper-parameters to text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/tmp.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the Results"
      ],
      "metadata": {
        "id": "VHVlK0YBDvc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view training curves\n",
        "# add code to visualize training accuracy "
      ],
      "metadata": {
        "id": "Oqp1QZ2qDw8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample some behavior\n",
        "# add code for psychometric curves"
      ],
      "metadata": {
        "id": "PT7d1KLBDyza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-pkcsUdbD0r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find attractor states"
      ],
      "metadata": {
        "id": "YHoyXbY9D2XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view some trajectories in state-space\n",
        "# pass to our provided plot function"
      ],
      "metadata": {
        "id": "tSf59qXXD4M9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}